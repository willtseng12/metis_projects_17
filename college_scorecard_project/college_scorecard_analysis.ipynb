{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "import re\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading data into Pandas\n",
    "I decided to read the most frequent csv dataset for this project. The data is from teh 2014-2015 school year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Desktop/CollegeScorecard_Raw_Data/MERGED2011_12_PP.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing round 1\n",
    "- remove features with only null values\n",
    "- remove features with only 1 value across all obs\n",
    "- turn certain features values into the string values that they represent (ie. `HIGHDEG`) is suppose to represent the highest degree awarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def drop_svf(df):\n",
    "    '''\n",
    "    drop single value features (where all observations in that column have only 1 value)\n",
    "    df : dataframe \n",
    "    return : dataframe\n",
    "    '''\n",
    "    df_cleaned = deepcopy(df)\n",
    "    for column in df.columns:\n",
    "        if len(df[column].value_counts()) == 1:\n",
    "            df_cleaned = df_cleaned.drop(column, axis = 1)\n",
    "    return df_cleaned\n",
    "\n",
    "def replace_category(df, col_name, name_key):\n",
    "    '''\n",
    "    replace the integer/float representation of values in a column \n",
    "    by the corresponding string values of name_key\n",
    "    \n",
    "    df : dataframe to operate on\n",
    "    col_name : a list of column names of which the replacement will take place\n",
    "    name_key : the corresponding replacement list of strings to which each of the values \n",
    "               in col_name will be replaced by\n",
    "               \n",
    "    return : the newly modified dataframe\n",
    "    '''\n",
    "    new_df = df.copy()\n",
    "    for col in col_name:\n",
    "#         assert str(df[col].dtype) == 'float64' or str(df[col].dtype) == 'int64'\n",
    "        new_col = []\n",
    "        for i,obs in enumerate(df[col]):\n",
    "            if np.isnan(obs):\n",
    "                str_val = np.nan\n",
    "            else:\n",
    "                str_val = name_key[int(obs)]\n",
    "            new_col.append(str_val)\n",
    "        new_df[col] = new_col\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNITID</th>\n",
       "      <th>OPEID</th>\n",
       "      <th>OPEID6</th>\n",
       "      <th>INSTNM</th>\n",
       "      <th>CITY</th>\n",
       "      <th>STABBR</th>\n",
       "      <th>ZIP</th>\n",
       "      <th>SCH_DEG</th>\n",
       "      <th>MAIN</th>\n",
       "      <th>NUMBRANCH</th>\n",
       "      <th>...</th>\n",
       "      <th>D100_L4</th>\n",
       "      <th>TRANS_4</th>\n",
       "      <th>DTRANS_4</th>\n",
       "      <th>TRANS_L4</th>\n",
       "      <th>DTRANS_L4</th>\n",
       "      <th>ICLEVEL</th>\n",
       "      <th>UGDS_MEN</th>\n",
       "      <th>UGDS_WOMEN</th>\n",
       "      <th>CDR3_DENOM</th>\n",
       "      <th>CDR2_DENOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100654</td>\n",
       "      <td>100200</td>\n",
       "      <td>1002</td>\n",
       "      <td>Alabama A &amp; M University</td>\n",
       "      <td>Normal</td>\n",
       "      <td>AL</td>\n",
       "      <td>35762</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>1438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100663</td>\n",
       "      <td>105200</td>\n",
       "      <td>1052</td>\n",
       "      <td>University of Alabama at Birmingham</td>\n",
       "      <td>Birmingham</td>\n",
       "      <td>AL</td>\n",
       "      <td>35294-0110</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.283168</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4154</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>2836.0</td>\n",
       "      <td>3160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100690</td>\n",
       "      <td>2503400</td>\n",
       "      <td>25034</td>\n",
       "      <td>Amridge University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>36117-3553</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4389</td>\n",
       "      <td>0.5611</td>\n",
       "      <td>315.0</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100706</td>\n",
       "      <td>105500</td>\n",
       "      <td>1055</td>\n",
       "      <td>University of Alabama in Huntsville</td>\n",
       "      <td>Huntsville</td>\n",
       "      <td>AL</td>\n",
       "      <td>35899</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.348243</td>\n",
       "      <td>626.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5402</td>\n",
       "      <td>0.4598</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>1208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100724</td>\n",
       "      <td>100500</td>\n",
       "      <td>1005</td>\n",
       "      <td>Alabama State University</td>\n",
       "      <td>Montgomery</td>\n",
       "      <td>AL</td>\n",
       "      <td>36104-0271</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>0.5946</td>\n",
       "      <td>2045.0</td>\n",
       "      <td>1957.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1585 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNITID    OPEID  OPEID6                               INSTNM        CITY  \\\n",
       "0  100654   100200    1002             Alabama A & M University      Normal   \n",
       "1  100663   105200    1052  University of Alabama at Birmingham  Birmingham   \n",
       "2  100690  2503400   25034                   Amridge University  Montgomery   \n",
       "3  100706   105500    1055  University of Alabama in Huntsville  Huntsville   \n",
       "4  100724   100500    1005             Alabama State University  Montgomery   \n",
       "\n",
       "  STABBR         ZIP  SCH_DEG  MAIN  NUMBRANCH     ...      D100_L4   TRANS_4  \\\n",
       "0     AL       35762      3.0     1          1     ...          NaN  0.000000   \n",
       "1     AL  35294-0110      3.0     1          1     ...          NaN  0.283168   \n",
       "2     AL  36117-3553      3.0     1          1     ...          NaN  0.000000   \n",
       "3     AL       35899      3.0     1          1     ...          NaN  0.348243   \n",
       "4     AL  36104-0271      3.0     1          1     ...          NaN  0.000000   \n",
       "\n",
       "   DTRANS_4  TRANS_L4  DTRANS_L4  ICLEVEL  UGDS_MEN  UGDS_WOMEN  CDR3_DENOM  \\\n",
       "0    1088.0       NaN        NaN        1    0.4786      0.5214      1514.0   \n",
       "1    1515.0       NaN        NaN        1    0.4154      0.5846      2836.0   \n",
       "2       4.0       NaN        NaN        1    0.4389      0.5611       315.0   \n",
       "3     626.0       NaN        NaN        1    0.5402      0.4598      1083.0   \n",
       "4    1198.0       NaN        NaN        1    0.4054      0.5946      2045.0   \n",
       "\n",
       "   CDR2_DENOM  \n",
       "0      1438.0  \n",
       "1      3160.0  \n",
       "2       266.0  \n",
       "3      1208.0  \n",
       "4      1957.0  \n",
       "\n",
       "[5 rows x 1585 columns]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.dropna(axis = 1, how='all')\n",
    "df = drop_svf(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "deg_name = ['not classified','certificate','associate','bachelor','graduate']\n",
    "control_name = ['','public', 'private_nonprofit', 'private_for-profit']\n",
    "region_name = ['us_service_schools', 'new_england', 'mid_east', 'great_lakes', 'plains',\n",
    "               'southeast', 'southwest', 'rocky_mountains', 'far_west', 'outlying_areas']\n",
    "iclevel_name = ['','4_year','2_year','less_than_2_year']\n",
    "\n",
    "# df = replace_category(df, ['HIGHDEG','PREDDEG'], deg_name)\n",
    "# df = replace_category(df, ['CONTROL'], control_name)\n",
    "# df = replace_category(df, ['REGION'], region_name)\n",
    "# df = replace_category(df, ['ICLEVEL'], iclevel_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### College University subset (Preprocessing round 2)\n",
    "\n",
    "- I am going to begin my analysis first with schools that have undergraduate students enrolled\n",
    "- I am going to drop certian redundant and unnecessary features (mostly names, zip codes, ids)\n",
    "- I am going to drop observation with more than 40% null values to insure quaity of our observations when we impute missing features later\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_row_missing(df, threshold):\n",
    "    '''\n",
    "    remove observations in df that has more than threshold% of null values\n",
    "    \n",
    "    df : a dataframe\n",
    "    threshold : the cuttoff ratio of unavailable data that will dictate the dropping of an observation\n",
    "    \n",
    "    return : a new dataframe with observations dropped\n",
    "    '''\n",
    "    new_df = df.copy()\n",
    "    length = len(df.columns)\n",
    "    \n",
    "    for i, row in df.iterrows():\n",
    "        num_nans = row.isnull().sum()\n",
    "        \n",
    "        ratio = num_nans / length\n",
    "        \n",
    "        if ratio > threshold:\n",
    "            new_df.drop(i, inplace = True)\n",
    "            \n",
    "    return new_df.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNITID</th>\n",
       "      <th>MAIN</th>\n",
       "      <th>NUMBRANCH</th>\n",
       "      <th>PREDDEG</th>\n",
       "      <th>HIGHDEG</th>\n",
       "      <th>CONTROL</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ADM_RATE</th>\n",
       "      <th>ADM_RATE_ALL</th>\n",
       "      <th>SATVR25</th>\n",
       "      <th>...</th>\n",
       "      <th>D100_L4</th>\n",
       "      <th>TRANS_4</th>\n",
       "      <th>DTRANS_4</th>\n",
       "      <th>TRANS_L4</th>\n",
       "      <th>DTRANS_L4</th>\n",
       "      <th>ICLEVEL</th>\n",
       "      <th>UGDS_MEN</th>\n",
       "      <th>UGDS_WOMEN</th>\n",
       "      <th>CDR3_DENOM</th>\n",
       "      <th>CDR2_DENOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>graduate</td>\n",
       "      <td>public</td>\n",
       "      <td>southeast</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>370.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_year</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>1438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100663</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>graduate</td>\n",
       "      <td>public</td>\n",
       "      <td>southeast</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.283168</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_year</td>\n",
       "      <td>0.4154</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>2836.0</td>\n",
       "      <td>3160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100690</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>graduate</td>\n",
       "      <td>private_nonprofit</td>\n",
       "      <td>southeast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_year</td>\n",
       "      <td>0.4389</td>\n",
       "      <td>0.5611</td>\n",
       "      <td>315.0</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100706</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>graduate</td>\n",
       "      <td>public</td>\n",
       "      <td>southeast</td>\n",
       "      <td>0.6368</td>\n",
       "      <td>0.6368</td>\n",
       "      <td>500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.348243</td>\n",
       "      <td>626.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_year</td>\n",
       "      <td>0.5402</td>\n",
       "      <td>0.4598</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>1208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100724</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>graduate</td>\n",
       "      <td>public</td>\n",
       "      <td>southeast</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_year</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>0.5946</td>\n",
       "      <td>2045.0</td>\n",
       "      <td>1957.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1575 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNITID  MAIN  NUMBRANCH   PREDDEG   HIGHDEG            CONTROL     REGION  \\\n",
       "0  100654     1          1  bachelor  graduate             public  southeast   \n",
       "1  100663     1          1  bachelor  graduate             public  southeast   \n",
       "2  100690     1          1  bachelor  graduate  private_nonprofit  southeast   \n",
       "3  100706     1          1  bachelor  graduate             public  southeast   \n",
       "4  100724     1          1  bachelor  graduate             public  southeast   \n",
       "\n",
       "   ADM_RATE  ADM_RATE_ALL  SATVR25     ...      D100_L4   TRANS_4  DTRANS_4  \\\n",
       "0    0.5010        0.5010    370.0     ...          NaN  0.000000    1088.0   \n",
       "1    0.7223        0.7223    500.0     ...          NaN  0.283168    1515.0   \n",
       "2       NaN           NaN      NaN     ...          NaN  0.000000       4.0   \n",
       "3    0.6368        0.6368    500.0     ...          NaN  0.348243     626.0   \n",
       "4    0.5080        0.5080    360.0     ...          NaN  0.000000    1198.0   \n",
       "\n",
       "   TRANS_L4  DTRANS_L4  ICLEVEL  UGDS_MEN  UGDS_WOMEN  CDR3_DENOM  CDR2_DENOM  \n",
       "0       NaN        NaN   4_year    0.4786      0.5214      1514.0      1438.0  \n",
       "1       NaN        NaN   4_year    0.4154      0.5846      2836.0      3160.0  \n",
       "2       NaN        NaN   4_year    0.4389      0.5611       315.0       266.0  \n",
       "3       NaN        NaN   4_year    0.5402      0.4598      1083.0      1208.0  \n",
       "4       NaN        NaN   4_year    0.4054      0.5946      2045.0      1957.0  \n",
       "\n",
       "[5 rows x 1575 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_college = df[df.UGDS > 0].reset_index(drop='True')\n",
    "df_college = df_college.drop(['OPEID','INSTNM','CITY','ZIP','OPEID6','ST_FIPS',\n",
    "                              'SCH_DEG','STABBR','REPAY_DT_MDN','ALIAS'], axis = 1)\n",
    "df_college = remove_row_missing(df_college, 0.8)\n",
    "df_college.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7042, 1575)"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_college.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deciding on which features to predict\n",
    "I am going to predict mean income after graduation from these schools. Since I am interested in the longer term mean earnings for graduates, I will be trying to predict `MN_EARN_WNE_P10`. Moreoever, there will generally more variabilty for earnings data the more years after graduation, possibly giving us more interesting results.\n",
    "\n",
    "- I will then remove all features that are other ways to represent earning information (ie. `MN_EARN_WNE_P6`)  because they are basically the same measure as my target variable.\n",
    "- I will also remove all information regarding repayment since that is also highly related to our target variable, diminishing the task of this project, which is to use static school information to predict post graduation earnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNITID</th>\n",
       "      <th>MAIN</th>\n",
       "      <th>NUMBRANCH</th>\n",
       "      <th>PREDDEG</th>\n",
       "      <th>HIGHDEG</th>\n",
       "      <th>CONTROL</th>\n",
       "      <th>REGION</th>\n",
       "      <th>ADM_RATE</th>\n",
       "      <th>ADM_RATE_ALL</th>\n",
       "      <th>SATVR25</th>\n",
       "      <th>...</th>\n",
       "      <th>D100_L4</th>\n",
       "      <th>TRANS_4</th>\n",
       "      <th>DTRANS_4</th>\n",
       "      <th>TRANS_L4</th>\n",
       "      <th>DTRANS_L4</th>\n",
       "      <th>ICLEVEL</th>\n",
       "      <th>UGDS_MEN</th>\n",
       "      <th>UGDS_WOMEN</th>\n",
       "      <th>CDR3_DENOM</th>\n",
       "      <th>CDR2_DENOM</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100654</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>graduate</td>\n",
       "      <td>public</td>\n",
       "      <td>southeast</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>0.5010</td>\n",
       "      <td>370.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1088.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_year</td>\n",
       "      <td>0.4786</td>\n",
       "      <td>0.5214</td>\n",
       "      <td>1514.0</td>\n",
       "      <td>1438.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100663</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>graduate</td>\n",
       "      <td>public</td>\n",
       "      <td>southeast</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>0.7223</td>\n",
       "      <td>500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.283168</td>\n",
       "      <td>1515.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_year</td>\n",
       "      <td>0.4154</td>\n",
       "      <td>0.5846</td>\n",
       "      <td>2836.0</td>\n",
       "      <td>3160.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100690</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>graduate</td>\n",
       "      <td>private_nonprofit</td>\n",
       "      <td>southeast</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_year</td>\n",
       "      <td>0.4389</td>\n",
       "      <td>0.5611</td>\n",
       "      <td>315.0</td>\n",
       "      <td>266.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100706</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>graduate</td>\n",
       "      <td>public</td>\n",
       "      <td>southeast</td>\n",
       "      <td>0.6368</td>\n",
       "      <td>0.6368</td>\n",
       "      <td>500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.348243</td>\n",
       "      <td>626.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_year</td>\n",
       "      <td>0.5402</td>\n",
       "      <td>0.4598</td>\n",
       "      <td>1083.0</td>\n",
       "      <td>1208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100724</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>bachelor</td>\n",
       "      <td>graduate</td>\n",
       "      <td>public</td>\n",
       "      <td>southeast</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>0.5080</td>\n",
       "      <td>360.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1198.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4_year</td>\n",
       "      <td>0.4054</td>\n",
       "      <td>0.5946</td>\n",
       "      <td>2045.0</td>\n",
       "      <td>1957.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 1401 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNITID  MAIN  NUMBRANCH   PREDDEG   HIGHDEG            CONTROL     REGION  \\\n",
       "0  100654     1          1  bachelor  graduate             public  southeast   \n",
       "1  100663     1          1  bachelor  graduate             public  southeast   \n",
       "2  100690     1          1  bachelor  graduate  private_nonprofit  southeast   \n",
       "3  100706     1          1  bachelor  graduate             public  southeast   \n",
       "4  100724     1          1  bachelor  graduate             public  southeast   \n",
       "\n",
       "   ADM_RATE  ADM_RATE_ALL  SATVR25     ...      D100_L4   TRANS_4  DTRANS_4  \\\n",
       "0    0.5010        0.5010    370.0     ...          NaN  0.000000    1088.0   \n",
       "1    0.7223        0.7223    500.0     ...          NaN  0.283168    1515.0   \n",
       "2       NaN           NaN      NaN     ...          NaN  0.000000       4.0   \n",
       "3    0.6368        0.6368    500.0     ...          NaN  0.348243     626.0   \n",
       "4    0.5080        0.5080    360.0     ...          NaN  0.000000    1198.0   \n",
       "\n",
       "   TRANS_L4  DTRANS_L4  ICLEVEL  UGDS_MEN  UGDS_WOMEN  CDR3_DENOM  CDR2_DENOM  \n",
       "0       NaN        NaN   4_year    0.4786      0.5214      1514.0      1438.0  \n",
       "1       NaN        NaN   4_year    0.4154      0.5846      2836.0      3160.0  \n",
       "2       NaN        NaN   4_year    0.4389      0.5611       315.0       266.0  \n",
       "3       NaN        NaN   4_year    0.5402      0.4598      1083.0      1208.0  \n",
       "4       NaN        NaN   4_year    0.4054      0.5946      2045.0      1957.0  \n",
       "\n",
       "[5 rows x 1401 columns]"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of column names on earnings that will be removed due to relationship with MN_EARN_WNE_P10\n",
    "loe = list(df_college.columns[df_college.columns.to_series().str.contains('_EARN_')][1:])\n",
    "loe.extend(list(df_college.columns[df_college.columns.to_series().str.contains('GT_')]))\n",
    "\n",
    "# list of column names on repayment that will be removed due too strong og a relationship with MN_EARN_WNE_P10\n",
    "lor = list(df_college.columns[df_college.columns.to_series().str.contains('RPY')])\n",
    "\n",
    "# list of column names on repayment that will be removed due too strong og a relationship with MN_EARN_WNE_P10\n",
    "lod = list(df_college.columns[df_college.columns.to_series().str.contains('DEBT')])\n",
    "\n",
    "df_college = df_college.drop(loe, axis = 1)\n",
    "df_college = df_college.drop(lor, axis = 1)\n",
    "df_college = df_college.drop(lod, axis = 1)\n",
    "df_college.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Removing features with too many nulls and privacy supressed columns and replace null values in each column by 0 (Preprocessing round 3)\n",
    "\n",
    "- I am also going to drop features that have more than 20% missing data as imputation later will be troublesome with so much missing values.\n",
    "- I am going to replace values in ordinal features will with 0 and create another binary value feature right after it indicating whether whether the corresponding value in the previous feature has nan.\n",
    "\n",
    "For categorical variables I can do the same because having null value for that observation inidicates the absence of its categorical quality, which is itself a category, a quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_col_missing(df, threshold):\n",
    "    '''\n",
    "    remove features in df that has more than threshold% of null values + privacy suppressed values\n",
    "    \n",
    "    df : a dataframe\n",
    "    threshold : the cuttoff ratio of unavailable data that will dictate the dropping of an features\n",
    "    \n",
    "    return : a new dataframe with features dropped\n",
    "    '''\n",
    "    new_df = df.copy()\n",
    "    length = len(df)\n",
    "    \n",
    "    for col in list(df.columns):\n",
    "        num_nans = df[col].isnull().sum()\n",
    "        ps = list(df[col]).count('PrivacySuppressed')\n",
    "        \n",
    "        ratio = (num_nans + ps) / length\n",
    "        \n",
    "        if ratio > threshold and col != 'MN_EARN_WNE_P10':\n",
    "            new_df.drop(col, axis = 1, inplace = True)\n",
    "            \n",
    "    return new_df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# let us create the binary features first\n",
    "def create_null_indicator(df):\n",
    "    '''\n",
    "    for every column in the dataframe with null values in it, create another 0/1 binary column \n",
    "    right after it indicating whether the corresponinf row obs in the previous column is null\n",
    "    \n",
    "    df : a dataframe\n",
    "    return : a dataframe with additional columns created\n",
    "    '''\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    for i in range(len(df.columns)):\n",
    "        \n",
    "        if not df[df.columns[i]].isnull().values.any():\n",
    "            continue\n",
    "            \n",
    "        null_indicator = []\n",
    "        \n",
    "        for obs in df[df.columns[i]]:\n",
    "            # np.nan == np.nan will yield false\n",
    "            if obs == obs:\n",
    "                null_indicator.append(0)\n",
    "            else:\n",
    "                null_indicator.append(1)\n",
    "                \n",
    "        col_name = str(df.columns[i]) + '_ISNULL'\n",
    "        index = list(new_df.columns).index(df.columns[i])\n",
    "        \n",
    "        new_df.insert(index + 1, column = col_name, value = np.array(null_indicator))\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_college = remove_col_missing(df_college, 0.6)\n",
    "df_college = create_null_indicator(df_college)\n",
    "df_college.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing out file for imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_college.to_csv('df_college3.csv',index=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Privacy suppressed columns\n",
    "\n",
    "After dealing with the null values, we still have privacy suppressed values in the dataset to handle. However, for these values, we can be sure that they exist but has been suppressed due to privacy issues usally for small schools with less people. Therefore, imputing them would be more acceptable than imputing missing values where we are not even able to determine whether its missing or do not apply\n",
    "\n",
    "I applied Multiple Imputation Chained Equation on the dataset for privacy suppressed value. SInce python does not have a good enough imputation package that support this method, I did the imputation in R. Now I am reading back the 5 completed imputed dataset into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chunks = pd.read_csv('imputed2.csv',chunksize=6750,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "completed_dfs = []\n",
    "for chunk in chunks:\n",
    "    completed_dfs.append(pd.DataFrame(chunk).reset_index(drop=True))\n",
    "completed_dfs = completed_dfs[1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove some collinear features\n",
    "\n",
    "When I was runnign the imputation in R, part of what the algorithm did was to drop features in teh imputation process that it deemed strongly collinear to one of the other features. Therefore, certain features still have NAs in them. We will take adavantage of this singal indicating that the correspoding feature is collinear to some other feature and can therefore be dropped without sacrificing our modeling power later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_collinear_col(dfs):\n",
    "    '''\n",
    "    remove columns in all dataframe that has null values in them\n",
    "    \n",
    "    dfs : list of dataframes\n",
    "    return : list of dataframes with null columns removed\n",
    "    '''\n",
    "    new_imputed_dfs = []\n",
    "    for df in dfs:\n",
    "        new_df = df.copy()\n",
    "        for col in df.columns:\n",
    "            if df[col].isnull().values.any():\n",
    "                new_df.drop(col, axis = 1, inplace = True)\n",
    "                try:\n",
    "                    new_df.drop(col + '_ISNULL', axis = 1, inplace = True)\n",
    "                except ValueError: # the column had no null values, which is fine\n",
    "                    pass\n",
    "        new_imputed_dfs.append(new_df)\n",
    "                \n",
    "    return new_imputed_dfs\n",
    "\n",
    "def remove_missing_target(dfs):\n",
    "    new_dfs = []\n",
    "    for df in dfs:\n",
    "        new_df = df.copy()\n",
    "        new_df = new_df.drop('MN_EARN_WNE_P10_ISNULL', axis = 1,)\n",
    "        new_df = df[df['MN_EARN_WNE_P10'] != 0]\n",
    "        new_dfs.append(new_df)\n",
    "    return new_dfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "dfs = remove_collinear_col(completed_dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove the 'ISNNULL' column for the target variable along with observations that has null in target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dfs = remove_missing_target(dfs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn each categorical feature into its own column of 0/1 binary indicator\n",
    "features such as `PREDDEG1`, `HIGHDEG`, `CONTROL` etc. are categorical variable, so we are goign to use patsy to turn them into multiple binary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import patsy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def binarify(df, col_name,):\n",
    "    '''\n",
    "    transform the categorical column specified by col_name in df into a binary column for each of the categories\n",
    "    \n",
    "    df : dataframe\n",
    "    col_name : list of categorical colum names in df that are to be transformed\n",
    "    '''\n",
    "    new_df = df.copy()\n",
    "    \n",
    "    for name in col_name:\n",
    "        col_position = list(new_df.columns).index(name)\n",
    "        \n",
    "        binarified = patsy.dmatrix(name,data=df,return_type='dataframe').drop(['Intercept',], axis = 1)\n",
    "        \n",
    "        for i,category in enumerate(binarified):\n",
    "            new_df.insert(col_position + i + 1, category, binarified[category])\n",
    "            \n",
    "        new_df = new_df.drop([name], axis = 1,)\n",
    "            \n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "'PREDDEG' is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-38-613a752b1ddc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'PREDDEG'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'HIGHDEG'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CONTROL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'REGION'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ICLEVEL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbinarify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-38-613a752b1ddc>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcategorical\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'PREDDEG'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'HIGHDEG'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'CONTROL'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'REGION'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'ICLEVEL'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdfs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbinarify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcategorical\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdfs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-37-a49bd4ae98e6>\u001b[0m in \u001b[0;36mbinarify\u001b[0;34m(df, col_name)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcol_name\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mcol_position\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mbinarified\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpatsy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dataframe'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Intercept'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: 'PREDDEG' is not in list"
     ]
    }
   ],
   "source": [
    "categorical = ['PREDDEG','HIGHDEG','CONTROL','REGION','ICLEVEL']\n",
    "dfs = [binarify(df,categorical) for df in dfs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Averaging the imputations\n",
    "\n",
    "Because I have 5 complete dataset after the imputation, I am going to average all the values across different dataframes together to get 1 complete dataframe.\n",
    "\n",
    "I am aware that this approach may slghtly diminish the uncertainty nature of the impuation because nwo I have a point estimate of the privacy suppressed value rather than a handful of them. However, Let us first see how this goes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def average_dataframes(dfs):\n",
    "    '''\n",
    "    average each cell across multiple dataframes \n",
    "    \n",
    "    dfs : list of dataframe\n",
    "    return : a dataframe with each cell corrected to the average across all dataframes in dfs (dataframe)\n",
    "    '''\n",
    "    col_names = dfs[0].columns[3:]\n",
    "    num_obs = len(dfs[0])\n",
    "    lst = []\n",
    "    for col in col_names:\n",
    "#         if col in categorical:\n",
    "#             lst.append(df[col])\n",
    "#             continue\n",
    "        col_sum = np.array([0]*num_obs)\n",
    "        \n",
    "        for df in dfs:\n",
    "            col_sum = col_sum + np.array(df[col])\n",
    "    \n",
    "        lst.append(col_sum / np.array([len(dfs)]*num_obs))\n",
    "        \n",
    "    \n",
    "    return pd.DataFrame(np.array(lst).T, columns=col_names)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_college = average_dataframes(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "intercept = np.array([1]*len(dfs[0]))\n",
    "df_college.insert(0, 'INTERCEPT',value = intercept)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning package imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.diagnostic import het_white, het_breuschpagan\n",
    "\n",
    "from sklearn.linear_model import RidgeCV,LassoCV, ElasticNetCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Standardizing our predictors\n",
    "This will be quite important if we decide to run a regression. Furthermore, I am goign to log transform the target variable as current literature have consistently shown that Earning data are usually log normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def standardize(df, lob):\n",
    "    '''\n",
    "    standardize columns that are not binary indicators in the dataframe\n",
    "    \n",
    "    df : dataframe\n",
    "    lob : list of partial matching strings for the features that will not be standardized\n",
    "    return : a standardized df\n",
    "    '''\n",
    "    new_df = df.copy()\n",
    "    for col in list(df.columns):\n",
    "        if True in [s in col for s in lob]:\n",
    "            continue\n",
    "        else:\n",
    "            mean = df[col].mean()\n",
    "            std = df[col].std()\n",
    "            new_df[col] = (df[col] - mean)/std\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "standardize(df_college,['PREDDEG','HIGHDEG','CONTOL','REGION','ICLEVEL','ISNULL','EARN','INTERCEPT'])\n",
    "\n",
    "# Emprically, earnings are typically lognormal\n",
    "df_college.MN_EARN_WNE_P10 = np.log(df_college.MN_EARN_WNE_P10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Lets take a quick look at the distribution of our target variable after transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x13b9ca278>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjIAAAGGCAYAAABhf2unAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x13b9a9f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, target_hist = plt.subplots(figsize = (9,6))\n",
    "plt.hist(df_college.MN_EARN_WNE_P10,bins = 18)\n",
    "plt.title('Post 6 years Mean Earnings Distribution', size = 17)\n",
    "plt.xlabel('log_earnings', size = 13)\n",
    "plt.ylabel('Frequency', size = 13)\n",
    "\n",
    "# roughly normal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test split\n",
    "I am going to split my dataset into train, test, and validation set first. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y = df_college.MN_EARN_WNE_P10\n",
    "X = df_college.drop('MN_EARN_WNE_P10', axis = 1)\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.25, random_state = 5555)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "Having removed certain collinear variables from the imputation process in R, we still have a relatively large feature space of 435 variables.\n",
    "\n",
    "We could do a number of things, run a ridge regression to deal with potentially persisting multicollinearity problem that still exists in our dataset   \n",
    "Please refer :  \n",
    "http://web.as.uky.edu/statistics/users/pbreheny/764-f11/notes/9-1.pdf\n",
    "\n",
    "We could also run Lasso for its embedded feature selection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_alpha(X_train, y_train, n_folds, alphas, l1_ratio = None,):\n",
    "    '''\n",
    "    use cross validation method to determine MSE of differnet penalty (alpha) parameters\n",
    "    in our l2 regularized model.\n",
    "    \n",
    "    X_train : feature matrix (dataframe)\n",
    "    y_train : target_variable (series, np.array, etc..)\n",
    "    n_folds : number of folds to divide up for cross valdation (int)\n",
    "    alphas : list of penalty parameter to test out (list)\n",
    "    return: MSE of different penalty parameters (list)\n",
    "    '''\n",
    "    kf = KFold(n=len(X_train), n_folds=n_folds, shuffle=True, random_state=5555)\n",
    "    alphas=alphas\n",
    "    all_mse_scores= np.array(len(alphas)*[0.0])\n",
    "\n",
    "    for train,test in kf:\n",
    "\n",
    "        X_cv_train= X_train.iloc[train]\n",
    "        y_cv_train= y_train.iloc[train]\n",
    "        X_cv_test= X_train.iloc[test]\n",
    "        y_cv_test= y_train.iloc[test]\n",
    "\n",
    "        mse_score=[]\n",
    "        for a in alphas:\n",
    "            est=Lasso(alpha=a, fit_intercept=False, max_iter=1000, tol = 0.004, normalize = True)\n",
    "            est.fit(X_cv_train,y_cv_train)\n",
    "            mse = np.mean((np.array((y_cv_test))-est.predict(X_cv_test))**2)\n",
    "            mse_score.append(mse)\n",
    "        all_mse_scores += mse_score\n",
    "\n",
    "    return all_mse_scores/len(alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.01424325,  0.01426117,  0.01419866,  0.01459247,  0.01435109,\n",
       "        0.01556794,  0.01989129,  0.47526807])"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_alpha(X_train, y_train, 5, alphas = [1e-8,1e-7,1e-6,1e-5,1e-4,1e-3,1e-2,1e-1,])\n",
    "\n",
    "# let us use 1e-2 as the penalty parameter for Ridge because it gives the lowest mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us define a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size = 0.25, random_state = 5555)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge\n",
      "MSE: 0.020833247939017398\n",
      "R2: 0.827284375665\n"
     ]
    }
   ],
   "source": [
    "# fitting and checking coef with ElasticNet\n",
    "\n",
    "rcv = RidgeCV(alphas = [1e-2], fit_intercept = True, cv = 10,)\n",
    "rcv.fit(X_train, y_train)\n",
    "\n",
    "# scoring our model on our validation set\n",
    "print('Ridge')\n",
    "print('MSE: ' + str(np.mean((rcv.predict(X_valid)-y_valid)**2)))\n",
    "print('R2: ' + str(rcv.score(X_valid,y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso\n",
      "MSE: 0.02007906371861281\n",
      "R2: 0.833536852421\n"
     ]
    }
   ],
   "source": [
    "# fitting and checking coef with Lasso\n",
    "\n",
    "lcv = LassoCV(alphas = [1e-5], tol=0.07, fit_intercept = True, max_iter=1000)\n",
    "lcv.fit(X_train, y_train)\n",
    "\n",
    "# scoring our model on our validation set\n",
    "print('Lasso')\n",
    "print('MSE: ' + str(np.mean((lcv.predict(X_valid)-y_valid)**2)))\n",
    "print('R2: ' + str(lcv.score(X_valid,y_valid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Implementing ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ElasticNet\n",
      "MSE: 0.022385231240662114\n",
      "R2: 0.814417838211\n"
     ]
    }
   ],
   "source": [
    "# fitting and checking coef with ElasticNet\n",
    "\n",
    "encv = ElasticNetCV(l1_ratio=0.5, alphas = [1e-5], fit_intercept = True, tol = 0.1, max_iter=1000)\n",
    "encv.fit(X_train, y_train)\n",
    "\n",
    "# scoring our model on our validation set\n",
    "print('ElasticNet')\n",
    "print('MSE: ' + str(np.mean((encv.predict(X_valid)-y_valid)**2)))\n",
    "print('R2: ' + str(encv.score(X_valid,y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest feature selection through feature importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rgs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-b20c99a9da1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# rgs.fit(X_train, y_train,)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrgs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_score_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rgs' is not defined"
     ]
    }
   ],
   "source": [
    "# Grid searching for optimal parameter\n",
    "\n",
    "rfr = RandomForestRegressor()\n",
    "\n",
    "# param_dist = dict(max_depth = [10,30,50,70,100], max_features = ['auto','sqrt'])\n",
    "\n",
    "# rgs = RandomizedSearchCV(rfr, param_dist, cv=10, scoring='neg_mean_squared_error',) \n",
    "# rgs.fit(X_train, y_train,)\n",
    "\n",
    "print(rgs.best_params_)\n",
    "print(rgs.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rfr = RandomForestRegressor(n_estimators=120,random_state=5555,)\n",
    "rffit = rfr.fit(X_train, y_train,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest\n",
      "R2: 0.862030761456\n",
      "MSE: 0.0166420806781\n"
     ]
    }
   ],
   "source": [
    "print('Random Forest')\n",
    "print('R2: ' + str(rfr.score(X_valid,y_valid)))\n",
    "print('MSE: ' + str(sum((rfr.predict(X_valid) - np.array(y_valid))**2)/len(y_valid)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ICLEVEL[T.4_year]', 0.20265168771626929),\n",
      " ('PCIP12', 0.15266231496954003),\n",
      " ('PREDDEG[T.bachelor]', 0.12417203398775419),\n",
      " ('FAMINC', 0.057666034078731318),\n",
      " ('DEP_INC_AVG', 0.045110133209228881),\n",
      " ('PELL_EVER', 0.033725161084088733),\n",
      " ('MD_FAMINC', 0.032244821885035045),\n",
      " ('COMP_ORIG_YR4_RT', 0.029764442804288336),\n",
      " ('UGDS_ASIAN', 0.027782488485094806),\n",
      " ('IND_INC_AVG', 0.022331773076523967),\n",
      " ('PCTPELL', 0.015595476685164318),\n",
      " ('INC_PCT_LO', 0.014211392634801293),\n",
      " ('PREDDEG[T.certificate]', 0.012493966790531308),\n",
      " ('INEXPFTE', 0.011280126551081741),\n",
      " ('COUNT_WNE_P10', 0.010411610021189116),\n",
      " ('FEMALE', 0.0085051110340020174),\n",
      " ('DEP_STAT_PCT_IND', 0.0071784839060488196),\n",
      " ('PCIP14', 0.0059841838683815894),\n",
      " ('UGDS', 0.0057340828819384326),\n",
      " ('COUNT_WNE_INC2_P10', 0.0053592101943376602),\n",
      " ('CDR2', 0.0053591683654925426),\n",
      " ('UGDS_WOMEN', 0.005185451704796621),\n",
      " ('UGDS_MEN', 0.0050356121394431871),\n",
      " ('UGDS_BLACK', 0.0047536044631672362),\n",
      " ('WDRAW_ORIG_YR2_RT', 0.004631574404780096),\n",
      " ('CDR3', 0.0045496330594698943),\n",
      " ('MALE_YR2_N', 0.0043686434186432314),\n",
      " ('UGDS_WHITE', 0.0041323047901168069),\n",
      " ('COMP_ORIG_YR6_RT', 0.0039508101999757746),\n",
      " ('PCIP50', 0.0039415441688236217),\n",
      " ('MALE_YR3_N', 0.0037701691701068538),\n",
      " ('INC_PCT_M1', 0.0035755640296218846),\n",
      " ('LOAN_EVER', 0.003498495681880012),\n",
      " ('DEPENDENT', 0.0034518669918605686),\n",
      " ('UGDS_HISP', 0.0034497384436329073),\n",
      " ('COUNT_WNE_MALE0_P10', 0.003414926200576394),\n",
      " ('MARRIED', 0.0033186514147937091),\n",
      " ('TUITFTE', 0.0031482734327887793),\n",
      " ('AGE_ENTRY', 0.0029883781058793355),\n",
      " ('APPL_SCH_PCT_GE2', 0.0029062231598095799),\n",
      " ('COUNT_WNE_INDEP0_P10', 0.0028643443129142132),\n",
      " ('PPTUG_EF', 0.002581530696983188),\n",
      " ('UGDS_UNKN', 0.0025654590500475455),\n",
      " ('CDR3_DENOM', 0.0024300537634767),\n",
      " ('CDR2_DENOM', 0.0021857083413739102),\n",
      " ('COUNT_NWNE_P8', 0.0021637620646935236),\n",
      " ('COUNT_WNE_MALE0_P6', 0.0021370820198627527),\n",
      " ('COMP_ORIG_YR2_RT', 0.0021354105964850787),\n",
      " ('COMP_ORIG_YR3_RT', 0.0021222053847616325)]\n"
     ]
    }
   ],
   "source": [
    "# top 20 most importan features\n",
    "\n",
    "feat_importance = sorted(list(zip(X.columns, rfr.feature_importances_)),key=lambda x : x[1], reverse=True)\n",
    "pprint(feat_importance[:49])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Taking the top features ranked according to feature importance\n",
    "\n",
    "I want to do some inference with regards to the explanatory power of the most importan variable in my Random Forest model. I am aware that because tree models are able to capture non-linear relationship, predictors that it deemed important may not be have a linear relationship with the target variable. Therefore, some trnasformation adn tweeking may be required when fine tuning the regression model.\n",
    "\n",
    "Another potential source of problem is that taking this amount of variable, some of them are highly liekly to be strng correlated with one another, leading us into the trap hole of multicollinearity, inflating our stnadard error, which will 'inaccuratize' the estimated coefficient p-value. Therefore, we need to remove some potentially highly correlated predictor variables before proceeding to model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sns.pairplot(pd.concat([X_train[top15],y_train],axis = 1))\n",
    "# f, ax = plt.subplots(figsize=(20, 16))\n",
    "# sns.heatmap(pd.concat([X_train[top15],y_train], axis = 1).corr(method = 'pearson'), linewidths=0.25,vmax=1.0, square=True, linecolor='black', annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from statsmodels.stats.outliers_influence import variance_inflation_factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "def multicollinearity_remover(predictor, target, threshold):\n",
    "    '''\n",
    "    remove predictor variables that have to a variance inflation factor above threshold\n",
    "    \n",
    "    predictor : predictor varaibles (matrix, dataframe etc.)\n",
    "    target : target variable vector (series, list, etc.)\n",
    "    threshold : a number above which a predictor variable will be deemed highly collinear with other predictor\n",
    "                and be dropped from final predictor matrix (int,float)\n",
    "    return : a predictor matrix with highly collinear varaibles dropped\n",
    "    '''\n",
    "    vifs = [threshold]\n",
    "    predictor_c = predictor.copy()\n",
    "    \n",
    "    model = sm.GLM(target, predictor_c)\n",
    "    result = model.fit()\n",
    "    \n",
    "    while list(filter(lambda x : x >= threshold, vifs)):\n",
    "    \n",
    "        predictor_name = pd.Series(result.params).index\n",
    "        current_vifs = []\n",
    "        for i in range(1,len(predictor_name)):\n",
    "            vif = variance_inflation_factor(result.model.exog, i)\n",
    "            current_vifs.append(vif)\n",
    "\n",
    "        vifs = current_vifs\n",
    "\n",
    "        # index of variable with highest vif\n",
    "        max_index = current_vifs.index(max(current_vifs))\n",
    "\n",
    "        # remove that variable\n",
    "        predictor_c = predictor_c.drop(predictor_name[max_index + 1], axis = 1)\n",
    "\n",
    "        model = sm.OLS(target, predictor_c)\n",
    "        result = model.fit()\n",
    "               \n",
    "       \n",
    "    return predictor_c\n",
    "               \n",
    "               \n",
    "               \n",
    "               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>INTERCEPT</th>\n",
       "      <th>PCIP12</th>\n",
       "      <th>PREDDEG[T.bachelor]</th>\n",
       "      <th>PELL_EVER</th>\n",
       "      <th>COMP_ORIG_YR4_RT</th>\n",
       "      <th>UGDS_ASIAN</th>\n",
       "      <th>IND_INC_AVG</th>\n",
       "      <th>PCTPELL</th>\n",
       "      <th>PREDDEG[T.certificate]</th>\n",
       "      <th>INEXPFTE</th>\n",
       "      <th>COUNT_WNE_P10</th>\n",
       "      <th>FEMALE</th>\n",
       "      <th>DEP_STAT_PCT_IND</th>\n",
       "      <th>PCIP14</th>\n",
       "      <th>UGDS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.225966</td>\n",
       "      <td>-1.280375</td>\n",
       "      <td>0.154592</td>\n",
       "      <td>0.537862</td>\n",
       "      <td>-0.783084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.220270</td>\n",
       "      <td>-0.053750</td>\n",
       "      <td>-0.332764</td>\n",
       "      <td>-0.298308</td>\n",
       "      <td>-0.058295</td>\n",
       "      <td>1.557100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.728734</td>\n",
       "      <td>-0.456400</td>\n",
       "      <td>0.005590</td>\n",
       "      <td>0.984734</td>\n",
       "      <td>-1.205044</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.059486</td>\n",
       "      <td>-0.127465</td>\n",
       "      <td>-0.221117</td>\n",
       "      <td>-1.471042</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>0.301898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2153</th>\n",
       "      <td>1</td>\n",
       "      <td>2.322517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.080040</td>\n",
       "      <td>0.571303</td>\n",
       "      <td>-0.200840</td>\n",
       "      <td>-0.051487</td>\n",
       "      <td>0.373089</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.217354</td>\n",
       "      <td>-0.270222</td>\n",
       "      <td>1.439205</td>\n",
       "      <td>-0.291800</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.388145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>1</td>\n",
       "      <td>2.278682</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.885032</td>\n",
       "      <td>0.751743</td>\n",
       "      <td>0.052153</td>\n",
       "      <td>-0.955477</td>\n",
       "      <td>1.025129</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.403018</td>\n",
       "      <td>-0.201632</td>\n",
       "      <td>1.419889</td>\n",
       "      <td>0.268036</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.005792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5391</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.388412</td>\n",
       "      <td>0.745165</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>1.287724</td>\n",
       "      <td>-1.090005</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.543492</td>\n",
       "      <td>-0.210285</td>\n",
       "      <td>1.436953</td>\n",
       "      <td>0.585590</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.398959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3277</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.160622</td>\n",
       "      <td>0.909515</td>\n",
       "      <td>-0.188423</td>\n",
       "      <td>0.554768</td>\n",
       "      <td>0.523662</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.148673</td>\n",
       "      <td>0.682349</td>\n",
       "      <td>-0.637773</td>\n",
       "      <td>-1.871082</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.339406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5277</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.737729</td>\n",
       "      <td>-0.764557</td>\n",
       "      <td>-0.436759</td>\n",
       "      <td>-0.377682</td>\n",
       "      <td>1.472407</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.413090</td>\n",
       "      <td>-0.111184</td>\n",
       "      <td>-0.670147</td>\n",
       "      <td>0.864659</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.327999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5706</th>\n",
       "      <td>1</td>\n",
       "      <td>0.128282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.849930</td>\n",
       "      <td>0.090071</td>\n",
       "      <td>-0.371571</td>\n",
       "      <td>-0.429223</td>\n",
       "      <td>0.977603</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.379164</td>\n",
       "      <td>-0.259369</td>\n",
       "      <td>1.125681</td>\n",
       "      <td>1.039640</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.332888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1270</th>\n",
       "      <td>1</td>\n",
       "      <td>1.644339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.088762</td>\n",
       "      <td>1.893566</td>\n",
       "      <td>-0.326560</td>\n",
       "      <td>-0.105270</td>\n",
       "      <td>0.325118</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.568804</td>\n",
       "      <td>-0.277308</td>\n",
       "      <td>1.470339</td>\n",
       "      <td>-0.285073</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.389034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5881</th>\n",
       "      <td>1</td>\n",
       "      <td>2.322517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602324</td>\n",
       "      <td>0.877874</td>\n",
       "      <td>-0.183767</td>\n",
       "      <td>-0.840496</td>\n",
       "      <td>1.186362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.303229</td>\n",
       "      <td>-0.238415</td>\n",
       "      <td>1.496807</td>\n",
       "      <td>0.355002</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.389182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6053</th>\n",
       "      <td>1</td>\n",
       "      <td>2.322517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.915876</td>\n",
       "      <td>0.371497</td>\n",
       "      <td>-0.199288</td>\n",
       "      <td>-0.999876</td>\n",
       "      <td>1.099750</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.211788</td>\n",
       "      <td>-0.258766</td>\n",
       "      <td>1.384925</td>\n",
       "      <td>0.610302</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.379701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2330</th>\n",
       "      <td>1</td>\n",
       "      <td>2.322517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.465931</td>\n",
       "      <td>1.097884</td>\n",
       "      <td>-0.064255</td>\n",
       "      <td>-0.870485</td>\n",
       "      <td>-0.612967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.611609</td>\n",
       "      <td>-0.274293</td>\n",
       "      <td>1.526313</td>\n",
       "      <td>0.601381</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.376886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4662</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.826379</td>\n",
       "      <td>0.021416</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>-0.369240</td>\n",
       "      <td>0.093262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.746217</td>\n",
       "      <td>-0.283187</td>\n",
       "      <td>-0.159272</td>\n",
       "      <td>0.969566</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.389478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3891</th>\n",
       "      <td>1</td>\n",
       "      <td>2.322517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.280505</td>\n",
       "      <td>0.674434</td>\n",
       "      <td>1.129311</td>\n",
       "      <td>0.548984</td>\n",
       "      <td>-0.741332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.406729</td>\n",
       "      <td>-0.276735</td>\n",
       "      <td>1.361684</td>\n",
       "      <td>0.669112</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.389626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.375116</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.526986</td>\n",
       "      <td>-1.089860</td>\n",
       "      <td>0.918226</td>\n",
       "      <td>-0.374924</td>\n",
       "      <td>0.191868</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.188597</td>\n",
       "      <td>-0.132892</td>\n",
       "      <td>0.193450</td>\n",
       "      <td>1.100645</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.167859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4119</th>\n",
       "      <td>1</td>\n",
       "      <td>0.680261</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.210877</td>\n",
       "      <td>-1.179510</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>-1.491068</td>\n",
       "      <td>-1.239690</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.625656</td>\n",
       "      <td>-0.279569</td>\n",
       "      <td>-1.792385</td>\n",
       "      <td>0.058856</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.376738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6082</th>\n",
       "      <td>1</td>\n",
       "      <td>1.391942</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.059738</td>\n",
       "      <td>0.311940</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>-0.839341</td>\n",
       "      <td>1.829519</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.591333</td>\n",
       "      <td>0.040317</td>\n",
       "      <td>0.865993</td>\n",
       "      <td>0.772475</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.345332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4110</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.989979</td>\n",
       "      <td>-1.589710</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>-0.755371</td>\n",
       "      <td>1.499502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.583249</td>\n",
       "      <td>-0.185201</td>\n",
       "      <td>-0.060500</td>\n",
       "      <td>-0.046075</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.246522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2918</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.389782</td>\n",
       "      <td>-1.842770</td>\n",
       "      <td>-0.446072</td>\n",
       "      <td>-0.004877</td>\n",
       "      <td>0.471250</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.020126</td>\n",
       "      <td>-0.186709</td>\n",
       "      <td>-0.175103</td>\n",
       "      <td>-0.059123</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.182969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4898</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.541970</td>\n",
       "      <td>0.882468</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>1.845783</td>\n",
       "      <td>0.756851</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.365779</td>\n",
       "      <td>-0.283337</td>\n",
       "      <td>1.330407</td>\n",
       "      <td>0.286659</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.401329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5213</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.599902</td>\n",
       "      <td>-1.011684</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>0.407045</td>\n",
       "      <td>0.163885</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.318071</td>\n",
       "      <td>8.094588</td>\n",
       "      <td>0.276122</td>\n",
       "      <td>1.593794</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.386071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2163</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.423725</td>\n",
       "      <td>1.578316</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>1.510065</td>\n",
       "      <td>-0.457508</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.604452</td>\n",
       "      <td>-0.274896</td>\n",
       "      <td>0.857988</td>\n",
       "      <td>0.933416</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.400144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.145143</td>\n",
       "      <td>-1.833907</td>\n",
       "      <td>5.237724</td>\n",
       "      <td>-0.756075</td>\n",
       "      <td>-1.820219</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.323107</td>\n",
       "      <td>-0.218818</td>\n",
       "      <td>-0.430148</td>\n",
       "      <td>-0.479044</td>\n",
       "      <td>-0.108994</td>\n",
       "      <td>0.817133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.439890</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.208861</td>\n",
       "      <td>-1.732213</td>\n",
       "      <td>0.120445</td>\n",
       "      <td>-0.116682</td>\n",
       "      <td>-0.972300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012872</td>\n",
       "      <td>-0.207210</td>\n",
       "      <td>-0.213174</td>\n",
       "      <td>-0.436774</td>\n",
       "      <td>0.004103</td>\n",
       "      <td>0.347525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.331353</td>\n",
       "      <td>0.585540</td>\n",
       "      <td>-0.093745</td>\n",
       "      <td>0.158289</td>\n",
       "      <td>-1.012719</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563601</td>\n",
       "      <td>-0.128671</td>\n",
       "      <td>-0.443630</td>\n",
       "      <td>-1.743861</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>0.169756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2945</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.251495</td>\n",
       "      <td>1.132391</td>\n",
       "      <td>-0.269132</td>\n",
       "      <td>1.605897</td>\n",
       "      <td>-0.286947</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.327181</td>\n",
       "      <td>-0.281679</td>\n",
       "      <td>0.904701</td>\n",
       "      <td>1.145186</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.370368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4149</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.116169</td>\n",
       "      <td>-0.224604</td>\n",
       "      <td>-0.455384</td>\n",
       "      <td>-2.109506</td>\n",
       "      <td>1.747792</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.232329</td>\n",
       "      <td>-0.200728</td>\n",
       "      <td>-0.544058</td>\n",
       "      <td>-1.217426</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>0.026355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2643</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.273766</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.179470</td>\n",
       "      <td>-1.107797</td>\n",
       "      <td>-0.424342</td>\n",
       "      <td>-0.284491</td>\n",
       "      <td>0.011979</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.111866</td>\n",
       "      <td>-0.226506</td>\n",
       "      <td>-0.135914</td>\n",
       "      <td>0.465365</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.130675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3123</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.250741</td>\n",
       "      <td>-1.012830</td>\n",
       "      <td>-0.253611</td>\n",
       "      <td>1.313637</td>\n",
       "      <td>0.166550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.245316</td>\n",
       "      <td>-0.213391</td>\n",
       "      <td>-0.078806</td>\n",
       "      <td>0.215309</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.188895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1671</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.136775</td>\n",
       "      <td>-1.255506</td>\n",
       "      <td>0.168561</td>\n",
       "      <td>0.620082</td>\n",
       "      <td>-1.030486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.189922</td>\n",
       "      <td>-0.166659</td>\n",
       "      <td>-0.429941</td>\n",
       "      <td>-0.463215</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>0.282936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2042</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.743003</td>\n",
       "      <td>-1.208975</td>\n",
       "      <td>0.039736</td>\n",
       "      <td>-0.186788</td>\n",
       "      <td>1.152606</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.089470</td>\n",
       "      <td>0.283472</td>\n",
       "      <td>-0.248137</td>\n",
       "      <td>0.146208</td>\n",
       "      <td>-0.036846</td>\n",
       "      <td>0.281454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4208</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.484550</td>\n",
       "      <td>-0.592847</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>-1.160416</td>\n",
       "      <td>0.051066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.332914</td>\n",
       "      <td>-0.273177</td>\n",
       "      <td>-2.152981</td>\n",
       "      <td>0.539666</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.395700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.434981</td>\n",
       "      <td>1.121475</td>\n",
       "      <td>7.111111</td>\n",
       "      <td>-0.777114</td>\n",
       "      <td>-0.717791</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.463694</td>\n",
       "      <td>0.387337</td>\n",
       "      <td>-0.478506</td>\n",
       "      <td>-1.929265</td>\n",
       "      <td>1.324218</td>\n",
       "      <td>2.852744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1827</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.121681</td>\n",
       "      <td>-1.850579</td>\n",
       "      <td>-0.255163</td>\n",
       "      <td>-1.120837</td>\n",
       "      <td>0.987819</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.397320</td>\n",
       "      <td>0.067451</td>\n",
       "      <td>-0.068409</td>\n",
       "      <td>0.453790</td>\n",
       "      <td>-0.153843</td>\n",
       "      <td>2.019597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.463343</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.094429</td>\n",
       "      <td>-1.327493</td>\n",
       "      <td>0.977205</td>\n",
       "      <td>-0.687018</td>\n",
       "      <td>-1.667425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.143009</td>\n",
       "      <td>-0.223189</td>\n",
       "      <td>-0.521291</td>\n",
       "      <td>-0.369913</td>\n",
       "      <td>-0.038796</td>\n",
       "      <td>0.829281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5504</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.898362</td>\n",
       "      <td>-0.290298</td>\n",
       "      <td>-0.132547</td>\n",
       "      <td>-0.510585</td>\n",
       "      <td>1.581229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.607103</td>\n",
       "      <td>-0.133947</td>\n",
       "      <td>0.554263</td>\n",
       "      <td>1.018920</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.336592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4961</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.089281</td>\n",
       "      <td>-1.518890</td>\n",
       "      <td>6.012223</td>\n",
       "      <td>-1.141412</td>\n",
       "      <td>1.750013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.546805</td>\n",
       "      <td>-0.265097</td>\n",
       "      <td>-0.086864</td>\n",
       "      <td>1.063484</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.335555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4042</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.393264</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.142693</td>\n",
       "      <td>-0.841743</td>\n",
       "      <td>-0.368467</td>\n",
       "      <td>0.970137</td>\n",
       "      <td>-1.512409</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.452680</td>\n",
       "      <td>-0.195301</td>\n",
       "      <td>0.013128</td>\n",
       "      <td>0.482183</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>0.138350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4219</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.839948</td>\n",
       "      <td>1.175438</td>\n",
       "      <td>-0.183767</td>\n",
       "      <td>1.737142</td>\n",
       "      <td>0.204749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.093809</td>\n",
       "      <td>-0.278514</td>\n",
       "      <td>1.506138</td>\n",
       "      <td>0.692480</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.397330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2215</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.726554</td>\n",
       "      <td>0.174784</td>\n",
       "      <td>-0.180662</td>\n",
       "      <td>0.686776</td>\n",
       "      <td>-0.558778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.064389</td>\n",
       "      <td>-0.183091</td>\n",
       "      <td>1.375913</td>\n",
       "      <td>-1.160203</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.172599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5127</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.411758</td>\n",
       "      <td>-0.352861</td>\n",
       "      <td>-0.019244</td>\n",
       "      <td>-0.033300</td>\n",
       "      <td>0.650694</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.345503</td>\n",
       "      <td>0.218349</td>\n",
       "      <td>-1.818420</td>\n",
       "      <td>0.853878</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.338666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6043</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.506055</td>\n",
       "      <td>-1.269048</td>\n",
       "      <td>-0.385540</td>\n",
       "      <td>0.499417</td>\n",
       "      <td>0.884772</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.606970</td>\n",
       "      <td>0.504618</td>\n",
       "      <td>0.164997</td>\n",
       "      <td>1.568503</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>0.284121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.184578</td>\n",
       "      <td>-0.670346</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>-0.668214</td>\n",
       "      <td>-0.243862</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.896630</td>\n",
       "      <td>-0.285297</td>\n",
       "      <td>-1.286176</td>\n",
       "      <td>0.104505</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.390663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.120838</td>\n",
       "      <td>-1.463919</td>\n",
       "      <td>3.561454</td>\n",
       "      <td>-0.488165</td>\n",
       "      <td>-1.900613</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.238690</td>\n",
       "      <td>-0.199824</td>\n",
       "      <td>-0.723148</td>\n",
       "      <td>-0.768352</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>1.300371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>1</td>\n",
       "      <td>2.322517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.247492</td>\n",
       "      <td>0.253536</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>-1.186038</td>\n",
       "      <td>1.704708</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.569201</td>\n",
       "      <td>-0.279720</td>\n",
       "      <td>0.724305</td>\n",
       "      <td>0.944602</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.395552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5850</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.506055</td>\n",
       "      <td>-1.269048</td>\n",
       "      <td>-0.095297</td>\n",
       "      <td>0.499417</td>\n",
       "      <td>-0.095066</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.558732</td>\n",
       "      <td>0.504618</td>\n",
       "      <td>0.164997</td>\n",
       "      <td>1.568503</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.306371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5299</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.723000</td>\n",
       "      <td>-1.304551</td>\n",
       "      <td>-0.107714</td>\n",
       "      <td>-0.320379</td>\n",
       "      <td>1.208127</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.438269</td>\n",
       "      <td>0.113278</td>\n",
       "      <td>-0.925874</td>\n",
       "      <td>-0.199124</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.225634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2819</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.615302</td>\n",
       "      <td>0.300003</td>\n",
       "      <td>-0.307935</td>\n",
       "      <td>1.251011</td>\n",
       "      <td>-1.412916</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.150396</td>\n",
       "      <td>-0.110430</td>\n",
       "      <td>0.172501</td>\n",
       "      <td>-1.587785</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>0.000726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2077</th>\n",
       "      <td>1</td>\n",
       "      <td>2.322517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.178782</td>\n",
       "      <td>0.476842</td>\n",
       "      <td>-0.121682</td>\n",
       "      <td>-0.893670</td>\n",
       "      <td>1.051335</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.359418</td>\n",
       "      <td>-0.284393</td>\n",
       "      <td>1.342400</td>\n",
       "      <td>-0.166623</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.398811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.405010</td>\n",
       "      <td>-1.098277</td>\n",
       "      <td>-0.126339</td>\n",
       "      <td>-0.441424</td>\n",
       "      <td>0.054619</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.533254</td>\n",
       "      <td>-0.123395</td>\n",
       "      <td>-0.167032</td>\n",
       "      <td>-1.754912</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>0.149164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5869</th>\n",
       "      <td>1</td>\n",
       "      <td>2.322517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602324</td>\n",
       "      <td>0.877874</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>-0.840496</td>\n",
       "      <td>0.678677</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.327083</td>\n",
       "      <td>-0.238415</td>\n",
       "      <td>1.496807</td>\n",
       "      <td>0.355002</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.389034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.743003</td>\n",
       "      <td>-1.208975</td>\n",
       "      <td>-0.050286</td>\n",
       "      <td>-0.186788</td>\n",
       "      <td>-0.477939</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.383405</td>\n",
       "      <td>0.283472</td>\n",
       "      <td>-0.248137</td>\n",
       "      <td>0.146208</td>\n",
       "      <td>-0.021246</td>\n",
       "      <td>0.207087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2824</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.332784</td>\n",
       "      <td>1.927941</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>0.546779</td>\n",
       "      <td>-0.610746</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.955618</td>\n",
       "      <td>-0.241731</td>\n",
       "      <td>-2.675961</td>\n",
       "      <td>0.626005</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.361924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6192</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.185509</td>\n",
       "      <td>0.463491</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>-0.973351</td>\n",
       "      <td>1.185474</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.803236</td>\n",
       "      <td>-0.123998</td>\n",
       "      <td>0.561312</td>\n",
       "      <td>1.017934</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.377182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>1</td>\n",
       "      <td>2.322517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.649132</td>\n",
       "      <td>0.015797</td>\n",
       "      <td>-0.466249</td>\n",
       "      <td>-0.980820</td>\n",
       "      <td>-0.748438</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.327215</td>\n",
       "      <td>-0.263740</td>\n",
       "      <td>1.132958</td>\n",
       "      <td>0.676371</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.396885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.197640</td>\n",
       "      <td>-0.234105</td>\n",
       "      <td>-0.082880</td>\n",
       "      <td>1.890680</td>\n",
       "      <td>-0.082185</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.146950</td>\n",
       "      <td>-0.049679</td>\n",
       "      <td>0.766603</td>\n",
       "      <td>1.421614</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.201339</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1686</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.905857</td>\n",
       "      <td>0.665334</td>\n",
       "      <td>0.232197</td>\n",
       "      <td>-0.669050</td>\n",
       "      <td>-1.214816</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.556180</td>\n",
       "      <td>-0.258313</td>\n",
       "      <td>-0.041618</td>\n",
       "      <td>-1.346983</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.336295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2658</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.034771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.142905</td>\n",
       "      <td>-1.508593</td>\n",
       "      <td>-0.421238</td>\n",
       "      <td>-0.972954</td>\n",
       "      <td>0.470362</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.059221</td>\n",
       "      <td>-0.249872</td>\n",
       "      <td>0.239562</td>\n",
       "      <td>0.567757</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.303556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4773</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.469485</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.996461</td>\n",
       "      <td>0.267533</td>\n",
       "      <td>0.697827</td>\n",
       "      <td>1.827594</td>\n",
       "      <td>-0.864811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.276194</td>\n",
       "      <td>-0.283337</td>\n",
       "      <td>1.232119</td>\n",
       "      <td>-0.754180</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.399552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5715</th>\n",
       "      <td>1</td>\n",
       "      <td>2.322517</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.602324</td>\n",
       "      <td>0.877874</td>\n",
       "      <td>0.019559</td>\n",
       "      <td>-0.840496</td>\n",
       "      <td>0.466364</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.131990</td>\n",
       "      <td>-0.238415</td>\n",
       "      <td>1.496807</td>\n",
       "      <td>0.355002</td>\n",
       "      <td>-0.167492</td>\n",
       "      <td>-0.395996</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3513 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      INTERCEPT    PCIP12  PREDDEG[T.bachelor]  PELL_EVER  COMP_ORIG_YR4_RT  \\\n",
       "3135          1 -0.469485                  0.0  -0.225966         -1.280375   \n",
       "1727          1 -0.469485                  1.0  -1.728734         -0.456400   \n",
       "2153          1  2.322517                  0.0   0.080040          0.571303   \n",
       "393           1  2.278682                  0.0   0.885032          0.751743   \n",
       "5391          1 -0.469485                  0.0  -2.388412          0.745165   \n",
       "3277          1 -0.469485                  0.0  -2.160622          0.909515   \n",
       "5277          1 -0.469485                  0.0   0.737729         -0.764557   \n",
       "5706          1  0.128282                  0.0   0.849930          0.090071   \n",
       "1270          1  1.644339                  0.0  -0.088762          1.893566   \n",
       "5881          1  2.322517                  0.0   0.602324          0.877874   \n",
       "6053          1  2.322517                  0.0   0.915876          0.371497   \n",
       "2330          1  2.322517                  0.0   0.465931          1.097884   \n",
       "4662          1 -0.469485                  1.0   0.826379          0.021416   \n",
       "3891          1  2.322517                  0.0  -0.280505          0.674434   \n",
       "381           1 -0.375116                  1.0   0.526986         -1.089860   \n",
       "4119          1  0.680261                  0.0   1.210877         -1.179510   \n",
       "6082          1  1.391942                  0.0   1.059738          0.311940   \n",
       "4110          1 -0.469485                  0.0   0.989979         -1.589710   \n",
       "2918          1 -0.469485                  0.0   0.389782         -1.842770   \n",
       "4898          1 -0.469485                  0.0  -0.541970          0.882468   \n",
       "5213          1 -0.469485                  1.0   0.599902         -1.011684   \n",
       "2163          1 -0.469485                  0.0  -0.423725          1.578316   \n",
       "433           1 -0.469485                  0.0   1.145143         -1.833907   \n",
       "639           1 -0.439890                  0.0   1.208861         -1.732213   \n",
       "2556          1 -0.469485                  1.0  -1.331353          0.585540   \n",
       "2945          1 -0.469485                  0.0   0.251495          1.132391   \n",
       "4149          1 -0.469485                  0.0   1.116169         -0.224604   \n",
       "2643          1 -0.273766                  0.0   1.179470         -1.107797   \n",
       "3123          1 -0.469485                  1.0  -0.250741         -1.012830   \n",
       "1671          1 -0.469485                  0.0  -0.136775         -1.255506   \n",
       "...         ...       ...                  ...        ...               ...   \n",
       "2042          1 -0.469485                  0.0   0.743003         -1.208975   \n",
       "4208          1 -0.469485                  1.0  -0.484550         -0.592847   \n",
       "244           1 -0.469485                  1.0  -0.434981          1.121475   \n",
       "1827          1 -0.469485                  0.0   1.121681         -1.850579   \n",
       "408           1 -0.463343                  0.0   1.094429         -1.327493   \n",
       "5504          1 -0.469485                  0.0   0.898362         -0.290298   \n",
       "4961          1 -0.469485                  0.0   1.089281         -1.518890   \n",
       "4042          1 -0.393264                  0.0  -0.142693         -0.841743   \n",
       "4219          1 -0.469485                  0.0  -0.839948          1.175438   \n",
       "2215          1 -0.469485                  1.0  -0.726554          0.174784   \n",
       "5127          1 -0.469485                  0.0   0.411758         -0.352861   \n",
       "6043          1 -0.469485                  1.0   0.506055         -1.269048   \n",
       "2591          1 -0.469485                  1.0  -0.184578         -0.670346   \n",
       "350           1 -0.469485                  0.0   1.120838         -1.463919   \n",
       "4506          1  2.322517                  0.0  -0.247492          0.253536   \n",
       "5850          1 -0.469485                  1.0   0.506055         -1.269048   \n",
       "5299          1 -0.469485                  1.0   0.723000         -1.304551   \n",
       "2819          1 -0.469485                  1.0  -1.615302          0.300003   \n",
       "2077          1  2.322517                  0.0  -0.178782          0.476842   \n",
       "663           1 -0.469485                  1.0  -0.405010         -1.098277   \n",
       "5869          1  2.322517                  0.0   0.602324          0.877874   \n",
       "2010          1 -0.469485                  0.0   0.743003         -1.208975   \n",
       "2824          1 -0.469485                  0.0  -0.332784          1.927941   \n",
       "6192          1 -0.469485                  0.0   1.185509          0.463491   \n",
       "4749          1  2.322517                  0.0   0.649132          0.015797   \n",
       "1073          1 -0.469485                  1.0  -1.197640         -0.234105   \n",
       "1686          1 -0.469485                  1.0  -1.905857          0.665334   \n",
       "2658          1 -0.034771                  0.0   1.142905         -1.508593   \n",
       "4773          1 -0.469485                  0.0  -0.996461          0.267533   \n",
       "5715          1  2.322517                  0.0   0.602324          0.877874   \n",
       "\n",
       "      UGDS_ASIAN  IND_INC_AVG   PCTPELL  PREDDEG[T.certificate]  INEXPFTE  \\\n",
       "3135    0.154592     0.537862 -0.783084                     0.0 -0.220270   \n",
       "1727    0.005590     0.984734 -1.205044                     0.0  0.059486   \n",
       "2153   -0.200840    -0.051487  0.373089                     1.0 -0.217354   \n",
       "393     0.052153    -0.955477  1.025129                     1.0 -0.403018   \n",
       "5391   -0.466249     1.287724 -1.090005                     1.0 -0.543492   \n",
       "3277   -0.188423     0.554768  0.523662                     0.0  0.148673   \n",
       "5277   -0.436759    -0.377682  1.472407                     1.0 -0.413090   \n",
       "5706   -0.371571    -0.429223  0.977603                     1.0 -0.379164   \n",
       "1270   -0.326560    -0.105270  0.325118                     1.0 -0.568804   \n",
       "5881   -0.183767    -0.840496  1.186362                     1.0 -0.303229   \n",
       "6053   -0.199288    -0.999876  1.099750                     1.0 -0.211788   \n",
       "2330   -0.064255    -0.870485 -0.612967                     1.0 -0.611609   \n",
       "4662   -0.466249    -0.369240  0.093262                     0.0  0.746217   \n",
       "3891    1.129311     0.548984 -0.741332                     1.0 -0.406729   \n",
       "381     0.918226    -0.374924  0.191868                     0.0 -0.188597   \n",
       "4119   -0.466249    -1.491068 -1.239690                     1.0 -0.625656   \n",
       "6082   -0.466249    -0.839341  1.829519                     1.0 -0.591333   \n",
       "4110   -0.466249    -0.755371  1.499502                     0.0 -0.583249   \n",
       "2918   -0.446072    -0.004877  0.471250                     0.0  0.020126   \n",
       "4898   -0.466249     1.845783  0.756851                     1.0 -0.365779   \n",
       "5213   -0.466249     0.407045  0.163885                     0.0 -0.318071   \n",
       "2163   -0.466249     1.510065 -0.457508                     1.0 -0.604452   \n",
       "433     5.237724    -0.756075 -1.820219                     0.0 -0.323107   \n",
       "639     0.120445    -0.116682 -0.972300                     0.0 -0.012872   \n",
       "2556   -0.093745     0.158289 -1.012719                     0.0  0.563601   \n",
       "2945   -0.269132     1.605897 -0.286947                     1.0  0.327181   \n",
       "4149   -0.455384    -2.109506  1.747792                     0.0 -0.232329   \n",
       "2643   -0.424342    -0.284491  0.011979                     0.0 -0.111866   \n",
       "3123   -0.253611     1.313637  0.166550                     0.0 -0.245316   \n",
       "1671    0.168561     0.620082 -1.030486                     0.0 -0.189922   \n",
       "...          ...          ...       ...                     ...       ...   \n",
       "2042    0.039736    -0.186788  1.152606                     0.0 -0.089470   \n",
       "4208   -0.466249    -1.160416  0.051066                     0.0 -0.332914   \n",
       "244     7.111111    -0.777114 -0.717791                     0.0  1.463694   \n",
       "1827   -0.255163    -1.120837  0.987819                     0.0 -0.397320   \n",
       "408     0.977205    -0.687018 -1.667425                     0.0 -0.143009   \n",
       "5504   -0.132547    -0.510585  1.581229                     0.0 -0.607103   \n",
       "4961    6.012223    -1.141412  1.750013                     1.0 -0.546805   \n",
       "4042   -0.368467     0.970137 -1.512409                     1.0  0.452680   \n",
       "4219   -0.183767     1.737142  0.204749                     1.0  0.093809   \n",
       "2215   -0.180662     0.686776 -0.558778                     0.0  0.064389   \n",
       "5127   -0.019244    -0.033300  0.650694                     0.0 -0.345503   \n",
       "6043   -0.385540     0.499417  0.884772                     0.0 -0.606970   \n",
       "2591   -0.466249    -0.668214 -0.243862                     0.0  0.896630   \n",
       "350     3.561454    -0.488165 -1.900613                     1.0 -0.238690   \n",
       "4506   -0.466249    -1.186038  1.704708                     1.0 -0.569201   \n",
       "5850   -0.095297     0.499417 -0.095066                     0.0 -0.558732   \n",
       "5299   -0.107714    -0.320379  1.208127                     0.0 -0.438269   \n",
       "2819   -0.307935     1.251011 -1.412916                     0.0  0.150396   \n",
       "2077   -0.121682    -0.893670  1.051335                     1.0 -0.359418   \n",
       "663    -0.126339    -0.441424  0.054619                     0.0  0.533254   \n",
       "5869   -0.466249    -0.840496  0.678677                     1.0 -0.327083   \n",
       "2010   -0.050286    -0.186788 -0.477939                     0.0 -0.383405   \n",
       "2824   -0.466249     0.546779 -0.610746                     1.0  1.955618   \n",
       "6192   -0.466249    -0.973351  1.185474                     0.0 -0.803236   \n",
       "4749   -0.466249    -0.980820 -0.748438                     1.0 -0.327215   \n",
       "1073   -0.082880     1.890680 -0.082185                     0.0  0.146950   \n",
       "1686    0.232197    -0.669050 -1.214816                     0.0  0.556180   \n",
       "2658   -0.421238    -0.972954  0.470362                     1.0  0.059221   \n",
       "4773    0.697827     1.827594 -0.864811                     1.0 -0.276194   \n",
       "5715    0.019559    -0.840496  0.466364                     1.0  1.131990   \n",
       "\n",
       "      COUNT_WNE_P10    FEMALE  DEP_STAT_PCT_IND    PCIP14      UGDS  \n",
       "3135      -0.053750 -0.332764         -0.298308 -0.058295  1.557100  \n",
       "1727      -0.127465 -0.221117         -1.471042 -0.167492  0.301898  \n",
       "2153      -0.270222  1.439205         -0.291800 -0.167492 -0.388145  \n",
       "393       -0.201632  1.419889          0.268036 -0.167492 -0.005792  \n",
       "5391      -0.210285  1.436953          0.585590 -0.167492 -0.398959  \n",
       "3277       0.682349 -0.637773         -1.871082 -0.167492 -0.339406  \n",
       "5277      -0.111184 -0.670147          0.864659 -0.167492 -0.327999  \n",
       "5706      -0.259369  1.125681          1.039640 -0.167492 -0.332888  \n",
       "1270      -0.277308  1.470339         -0.285073 -0.167492 -0.389034  \n",
       "5881      -0.238415  1.496807          0.355002 -0.167492 -0.389182  \n",
       "6053      -0.258766  1.384925          0.610302 -0.167492 -0.379701  \n",
       "2330      -0.274293  1.526313          0.601381 -0.167492 -0.376886  \n",
       "4662      -0.283187 -0.159272          0.969566 -0.167492 -0.389478  \n",
       "3891      -0.276735  1.361684          0.669112 -0.167492 -0.389626  \n",
       "381       -0.132892  0.193450          1.100645 -0.167492 -0.167859  \n",
       "4119      -0.279569 -1.792385          0.058856 -0.167492 -0.376738  \n",
       "6082       0.040317  0.865993          0.772475 -0.167492 -0.345332  \n",
       "4110      -0.185201 -0.060500         -0.046075 -0.167492 -0.246522  \n",
       "2918      -0.186709 -0.175103         -0.059123 -0.167492 -0.182969  \n",
       "4898      -0.283337  1.330407          0.286659 -0.167492 -0.401329  \n",
       "5213       8.094588  0.276122          1.593794 -0.167492 -0.386071  \n",
       "2163      -0.274896  0.857988          0.933416 -0.167492 -0.400144  \n",
       "433       -0.218818 -0.430148         -0.479044 -0.108994  0.817133  \n",
       "639       -0.207210 -0.213174         -0.436774  0.004103  0.347525  \n",
       "2556      -0.128671 -0.443630         -1.743861 -0.167492  0.169756  \n",
       "2945      -0.281679  0.904701          1.145186 -0.167492 -0.370368  \n",
       "4149      -0.200728 -0.544058         -1.217426 -0.167492  0.026355  \n",
       "2643      -0.226506 -0.135914          0.465365 -0.167492 -0.130675  \n",
       "3123      -0.213391 -0.078806          0.215309 -0.167492 -0.188895  \n",
       "1671      -0.166659 -0.429941         -0.463215 -0.167492  0.282936  \n",
       "...             ...       ...               ...       ...       ...  \n",
       "2042       0.283472 -0.248137          0.146208 -0.036846  0.281454  \n",
       "4208      -0.273177 -2.152981          0.539666 -0.167492 -0.395700  \n",
       "244        0.387337 -0.478506         -1.929265  1.324218  2.852744  \n",
       "1827       0.067451 -0.068409          0.453790 -0.153843  2.019597  \n",
       "408       -0.223189 -0.521291         -0.369913 -0.038796  0.829281  \n",
       "5504      -0.133947  0.554263          1.018920 -0.167492 -0.336592  \n",
       "4961      -0.265097 -0.086864          1.063484 -0.167492 -0.335555  \n",
       "4042      -0.195301  0.013128          0.482183 -0.167492  0.138350  \n",
       "4219      -0.278514  1.506138          0.692480 -0.167492 -0.397330  \n",
       "2215      -0.183091  1.375913         -1.160203 -0.167492 -0.172599  \n",
       "5127       0.218349 -1.818420          0.853878 -0.167492 -0.338666  \n",
       "6043       0.504618  0.164997          1.568503 -0.167492  0.284121  \n",
       "2591      -0.285297 -1.286176          0.104505 -0.167492 -0.390663  \n",
       "350       -0.199824 -0.723148         -0.768352 -0.167492  1.300371  \n",
       "4506      -0.279720  0.724305          0.944602 -0.167492 -0.395552  \n",
       "5850       0.504618  0.164997          1.568503 -0.167492 -0.306371  \n",
       "5299       0.113278 -0.925874         -0.199124 -0.167492 -0.225634  \n",
       "2819      -0.110430  0.172501         -1.587785 -0.167492  0.000726  \n",
       "2077      -0.284393  1.342400         -0.166623 -0.167492 -0.398811  \n",
       "663       -0.123395 -0.167032         -1.754912 -0.167492  0.149164  \n",
       "5869      -0.238415  1.496807          0.355002 -0.167492 -0.389034  \n",
       "2010       0.283472 -0.248137          0.146208 -0.021246  0.207087  \n",
       "2824      -0.241731 -2.675961          0.626005 -0.167492 -0.361924  \n",
       "6192      -0.123998  0.561312          1.017934 -0.167492 -0.377182  \n",
       "4749      -0.263740  1.132958          0.676371 -0.167492 -0.396885  \n",
       "1073      -0.049679  0.766603          1.421614 -0.167492 -0.201339  \n",
       "1686      -0.258313 -0.041618         -1.346983 -0.167492 -0.336295  \n",
       "2658      -0.249872  0.239562          0.567757 -0.167492 -0.303556  \n",
       "4773      -0.283337  1.232119         -0.754180 -0.167492 -0.399552  \n",
       "5715      -0.238415  1.496807          0.355002 -0.167492 -0.395996  \n",
       "\n",
       "[3513 rows x 15 columns]"
      ]
     },
     "execution_count": 370,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multicollinearity_remover(standardize(X_train[top20],['PREDDEG','HIGHDEG','CONTOL','REGION','ICLEVEL','ISNULL','EARN','INTERCEPT']), y_train, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "top20 = list(map(lambda x : x[0], feat_importance[:19]))\n",
    "top20.insert(0,'INTERCEPT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# lr = sm.OLS(((np.exp(y_train) - np.mean(np.exp(y_train)))/np.std(np.exp(y_train))), X_train[top12])\n",
    "lr = sm.OLS(y_train, multicollinearity_remover(multicollinearity_remover(standardize(X_train[top20],['PREDDEG','HIGHDEG','CONTOL','REGION','ICLEVEL','ISNULL','EARN','INTERCEPT']), y_train, 5), y_train, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>MN_EARN_WNE_P10</td> <th>  R-squared:         </th> <td>   0.795</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.794</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   501.1</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 02 Sep 2017</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:26:00</td>     <th>  Log-Likelihood:    </th> <td>  1545.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  3513</td>      <th>  AIC:               </th> <td>  -3035.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  3485</td>      <th>  BIC:               </th> <td>  -2863.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    27</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INTERCEPT</th>              <td>   10.4279</td> <td>    0.007</td> <td> 1441.456</td> <td> 0.000</td> <td>   10.414</td> <td>   10.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ICLEVEL[T.4_year]</th>      <td>    0.0520</td> <td>    0.011</td> <td>    4.772</td> <td> 0.000</td> <td>    0.031</td> <td>    0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCIP12</th>                 <td>   -0.0994</td> <td>    0.003</td> <td>  -28.873</td> <td> 0.000</td> <td>   -0.106</td> <td>   -0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PREDDEG[T.bachelor]</th>    <td>   -0.0044</td> <td>    0.012</td> <td>   -0.379</td> <td> 0.705</td> <td>   -0.027</td> <td>    0.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UGDS_ASIAN</th>             <td>    0.0316</td> <td>    0.003</td> <td>   11.084</td> <td> 0.000</td> <td>    0.026</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>IND_INC_AVG</th>            <td>    0.0803</td> <td>    0.004</td> <td>   20.487</td> <td> 0.000</td> <td>    0.073</td> <td>    0.088</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCTPELL</th>                <td>   -0.0462</td> <td>    0.004</td> <td>  -12.072</td> <td> 0.000</td> <td>   -0.054</td> <td>   -0.039</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PREDDEG[T.certificate]</th> <td>   -0.0555</td> <td>    0.009</td> <td>   -6.131</td> <td> 0.000</td> <td>   -0.073</td> <td>   -0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INEXPFTE</th>               <td>    0.0464</td> <td>    0.003</td> <td>   15.218</td> <td> 0.000</td> <td>    0.040</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCIP14</th>                 <td>    0.0308</td> <td>    0.003</td> <td>   10.929</td> <td> 0.000</td> <td>    0.025</td> <td>    0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UGDS</th>                   <td>    0.0114</td> <td>    0.003</td> <td>    3.849</td> <td> 0.000</td> <td>    0.006</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CDR2</th>                   <td>    0.0057</td> <td>    0.004</td> <td>    1.427</td> <td> 0.154</td> <td>   -0.002</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UGDS_WOMEN</th>             <td>   -0.0586</td> <td>    0.003</td> <td>  -16.875</td> <td> 0.000</td> <td>   -0.065</td> <td>   -0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UGDS_BLACK</th>             <td>    0.0040</td> <td>    0.003</td> <td>    1.213</td> <td> 0.225</td> <td>   -0.002</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>WDRAW_ORIG_YR2_RT</th>      <td>    0.0097</td> <td>    0.004</td> <td>    2.650</td> <td> 0.008</td> <td>    0.003</td> <td>    0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CDR3</th>                   <td>   -0.0066</td> <td>    0.004</td> <td>   -1.585</td> <td> 0.113</td> <td>   -0.015</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COMP_ORIG_YR6_RT</th>       <td>    0.0605</td> <td>    0.004</td> <td>   16.423</td> <td> 0.000</td> <td>    0.053</td> <td>    0.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PCIP50</th>                 <td>   -0.0239</td> <td>    0.003</td> <td>   -8.299</td> <td> 0.000</td> <td>   -0.030</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INC_PCT_M1</th>             <td>    0.0127</td> <td>    0.003</td> <td>    3.648</td> <td> 0.000</td> <td>    0.006</td> <td>    0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UGDS_HISP</th>              <td>   -0.0019</td> <td>    0.003</td> <td>   -0.605</td> <td> 0.545</td> <td>   -0.008</td> <td>    0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COUNT_WNE_MALE0_P10</th>    <td>    0.0583</td> <td>    0.003</td> <td>   17.938</td> <td> 0.000</td> <td>    0.052</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>MARRIED</th>                <td>   -0.0256</td> <td>    0.004</td> <td>   -6.176</td> <td> 0.000</td> <td>   -0.034</td> <td>   -0.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TUITFTE</th>                <td>    0.0225</td> <td>    0.003</td> <td>    6.585</td> <td> 0.000</td> <td>    0.016</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE_ENTRY</th>              <td>    0.0112</td> <td>    0.005</td> <td>    2.280</td> <td> 0.023</td> <td>    0.002</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>APPL_SCH_PCT_GE2</th>       <td>    0.0423</td> <td>    0.004</td> <td>   10.013</td> <td> 0.000</td> <td>    0.034</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>COUNT_WNE_INDEP0_P10</th>   <td>    0.0089</td> <td>    0.003</td> <td>    2.860</td> <td> 0.004</td> <td>    0.003</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PPTUG_EF</th>               <td>    0.0222</td> <td>    0.003</td> <td>    6.494</td> <td> 0.000</td> <td>    0.015</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>UGDS_UNKN</th>              <td>    0.0122</td> <td>    0.003</td> <td>    4.117</td> <td> 0.000</td> <td>    0.006</td> <td>    0.018</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>151.824</td> <th>  Durbin-Watson:     </th> <td>   1.981</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 407.606</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.194</td>  <th>  Prob(JB):          </th> <td>3.09e-89</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 4.623</td>  <th>  Cond. No.          </th> <td>    11.1</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:        MN_EARN_WNE_P10   R-squared:                       0.795\n",
       "Model:                            OLS   Adj. R-squared:                  0.794\n",
       "Method:                 Least Squares   F-statistic:                     501.1\n",
       "Date:                Sat, 02 Sep 2017   Prob (F-statistic):               0.00\n",
       "Time:                        10:26:00   Log-Likelihood:                 1545.6\n",
       "No. Observations:                3513   AIC:                            -3035.\n",
       "Df Residuals:                    3485   BIC:                            -2863.\n",
       "Df Model:                          27                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "INTERCEPT                 10.4279      0.007   1441.456      0.000      10.414      10.442\n",
       "ICLEVEL[T.4_year]          0.0520      0.011      4.772      0.000       0.031       0.073\n",
       "PCIP12                    -0.0994      0.003    -28.873      0.000      -0.106      -0.093\n",
       "PREDDEG[T.bachelor]       -0.0044      0.012     -0.379      0.705      -0.027       0.019\n",
       "UGDS_ASIAN                 0.0316      0.003     11.084      0.000       0.026       0.037\n",
       "IND_INC_AVG                0.0803      0.004     20.487      0.000       0.073       0.088\n",
       "PCTPELL                   -0.0462      0.004    -12.072      0.000      -0.054      -0.039\n",
       "PREDDEG[T.certificate]    -0.0555      0.009     -6.131      0.000      -0.073      -0.038\n",
       "INEXPFTE                   0.0464      0.003     15.218      0.000       0.040       0.052\n",
       "PCIP14                     0.0308      0.003     10.929      0.000       0.025       0.036\n",
       "UGDS                       0.0114      0.003      3.849      0.000       0.006       0.017\n",
       "CDR2                       0.0057      0.004      1.427      0.154      -0.002       0.014\n",
       "UGDS_WOMEN                -0.0586      0.003    -16.875      0.000      -0.065      -0.052\n",
       "UGDS_BLACK                 0.0040      0.003      1.213      0.225      -0.002       0.011\n",
       "WDRAW_ORIG_YR2_RT          0.0097      0.004      2.650      0.008       0.003       0.017\n",
       "CDR3                      -0.0066      0.004     -1.585      0.113      -0.015       0.002\n",
       "COMP_ORIG_YR6_RT           0.0605      0.004     16.423      0.000       0.053       0.068\n",
       "PCIP50                    -0.0239      0.003     -8.299      0.000      -0.030      -0.018\n",
       "INC_PCT_M1                 0.0127      0.003      3.648      0.000       0.006       0.020\n",
       "UGDS_HISP                 -0.0019      0.003     -0.605      0.545      -0.008       0.004\n",
       "COUNT_WNE_MALE0_P10        0.0583      0.003     17.938      0.000       0.052       0.065\n",
       "MARRIED                   -0.0256      0.004     -6.176      0.000      -0.034      -0.017\n",
       "TUITFTE                    0.0225      0.003      6.585      0.000       0.016       0.029\n",
       "AGE_ENTRY                  0.0112      0.005      2.280      0.023       0.002       0.021\n",
       "APPL_SCH_PCT_GE2           0.0423      0.004     10.013      0.000       0.034       0.051\n",
       "COUNT_WNE_INDEP0_P10       0.0089      0.003      2.860      0.004       0.003       0.015\n",
       "PPTUG_EF                   0.0222      0.003      6.494      0.000       0.015       0.029\n",
       "UGDS_UNKN                  0.0122      0.003      4.117      0.000       0.006       0.018\n",
       "==============================================================================\n",
       "Omnibus:                      151.824   Durbin-Watson:                   1.981\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              407.606\n",
       "Skew:                           0.194   Prob(JB):                     3.09e-89\n",
       "Kurtosis:                       4.623   Cond. No.                         11.1\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 382,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = lr.fit()\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCIP12\n",
      "0.3581149522982143\n",
      "-0.0333365692193\n",
      "PREDDEG[T.bachelor]\n",
      "0.4708988937853987\n",
      "0.0800237247076\n",
      "COMP_ORIG_YR4_RT\n",
      "0.2138693781933767\n",
      "0.060337982025\n",
      "UGDS_ASIAN\n",
      "0.0644196048892392\n",
      "0.0321001313011\n",
      "IND_INC_AVG\n",
      "8842.194842124121\n",
      "0.0895137580997\n",
      "PCTPELL\n",
      "0.22510738875597874\n",
      "-0.0504523572945\n",
      "PREDDEG[T.certificate]\n",
      "0.4954083407335203\n",
      "-0.115646960922\n",
      "INEXPFTE\n",
      "7544.812118971085\n",
      "0.0484120098415\n",
      "COUNT_WNE_P10\n",
      "6632.678674587419\n",
      "0.0662260278496\n",
      "FEMALE\n",
      "0.19946834241481348\n",
      "-0.0524976656464\n",
      "DEP_STAT_PCT_IND\n",
      "0.23549014946394894\n",
      "0.00172047730075\n",
      "PCIP14\n",
      "0.05127610213687764\n",
      "0.0312264513244\n",
      "UGDS\n",
      "6749.347380874676\n",
      "0.0162099119867\n"
     ]
    }
   ],
   "source": [
    "params = pd.Series(result.params)\n",
    "for i in range(1,len(params)):\n",
    "    print(params.index[i])\n",
    "    print(np.std(X_train[top20][params.index[i]]))\n",
    "    print(params[i])\n",
    "    params[i] = params[i] * np.std(X_train[top20][params.index[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INTERCEPT                  10.447874\n",
       "PCIP12                     -0.011938\n",
       "PREDDEG[T.bachelor]         0.037683\n",
       "COMP_ORIG_YR4_RT            0.012904\n",
       "UGDS_ASIAN                  0.002068\n",
       "IND_INC_AVG               791.498090\n",
       "PCTPELL                    -0.011357\n",
       "PREDDEG[T.certificate]     -0.057292\n",
       "INEXPFTE                  365.259519\n",
       "COUNT_WNE_P10             439.255963\n",
       "FEMALE                     -0.010472\n",
       "DEP_STAT_PCT_IND            0.000405\n",
       "PCIP14                      0.001601\n",
       "UGDS                      109.406327\n",
       "dtype: float64"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x132529b38>"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAD5CAYAAAAtBi5vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJztvXmYHOV17//pZbp7RjOjWdRCK8FoeeWgBYEQEgILZGEC\nN4qVCwZbhsTGa1bHTp784hvHmFw713HiJE7udWLzg+DlysGJbS75JTYXIQxaLBZp0ALoHUkYgzZm\n69lnev/90VOjnp6q6u7qdXrO53n0PJqu6qr37eo+deq853yPK5lMIgiCINQe7koPQBAEQSgNYuAF\nQRBqFDHwgiAINYoYeEEQhBpFDLwgCEKNIgZeEAShRvE6eZNSyg18HVgHhIGPaq1Pp23/IPCHQBx4\nRGv9j0UYqyAIgpAHjgw8sBMIaK03K6U2AV8F3pu2/a+Bq4Bh4FWl1L9orUN2B+zuHqrZhPzW1gZC\nodFKD6Ok1Poca31+UPtzrNX5BYNNLqttTkM0NwI/AdBaHwI2ZGw/BswFAoALqFnjnQter6fSQyg5\ntT7HWp8f1P4ca31+Zjg18M3AQNrfcaVU+tPACeAw8Arw/2mt+x2eRxAEQXCI0xDNINCU9rdbax0D\nUEqtBf4L8A5SIZrvKqXep7X+V7sDtrY21PQdNhhsyr7TDKfW51jr84Pan2Otzy8Tpwb+ALAD+P5E\nDP542rYBYAwY01rHlVJdQGu2A9ZibMwgGGyiu3uo0sMoKbU+x1qfH9T+HGt1fnY3LacG/kfArUqp\ng6Ri7B9WSu0CGrXW31RKfQPYr5SKAGeARx2eRxAEQXCIIwOvtU4An8x4+WTa9n8C/qmAcQmCIAgF\nIoVOgiAINYoYeKGohKNxukKjhKPxSg9FEGY9TmPwgjCFeDzB7j2ddHR20zcYpq3Zz/qVQe7ZthyP\nW/wIQagEYuCFovDIv7/CnpfOTv7dOxie/HvX9pWVGpYgzGrEtRIKJhyNc+jEBdNtHZ09FQ3XSMhI\nmM2IBy8UzMBwmO7+MdNtoaFxBobDzG9tKOuY4okEj+09LSEjYVYj33ShYOY2+gm21Jtua20KMLfR\nX+YRwWN7T7PnpbP0DoZJcilk9Nje01nfKwi1ghh4wZR8Qhv+Og+bVi803bZ+5Tz8deWVoAhH43R0\ndptuq3TISBDKiYRohCk4DW3cv+MqRscidHT2EBoap7UpwPqV87hn2/Iyjj7FwHCYvsGw6bZKhYwE\noRKIgRemYIQ2DHLNhvF43OzavpI7ty5jYDjM3EZ/2T13g7mNftqa/fSaGPlKhYwEoRJIiEaYpBih\nDX+dh/mtDRUz7sYY1q8Mmm7LNWQk2TdCLSAevDBJLYU2jNBQviEjqxDV7969vhzDFoSiIgZemKSW\nQhset7OQkVWIqqHex84tV5RwxIJQfCREI0xSjNBGMTHCJEOjEcfhknxCRnYhqkMnLki4RphxiAcv\nTMFpaKOYGGGSI7qLvqEIbhckktBe4mIluxBVT//YjApRCQKIgRcycBraKCaZYZLERMv2Uuvb2IWo\n5rXUFxSiCkfjFc8uEmYfYuAFU4zQRrmxC5MYdHT2cOfWZUU3lEaIKv3mYrBp9UJH5xPJBKGSiIEX\nqgLDw43EEpZhEoNSZvRYhaju33EVfX0jeR/PaV2BIBQDMfBCRcn0cFubfLjdLuJGXMaEUmb0WIWo\nPJ78ve1sdQWleAoRhHQcGXillBv4OrAOCAMf1VqfTtt+HfA3pBpyXwTu1VqPFz7c0iEx0sqQ6eH2\nDUWyvqccGT3FCFHVUl2BMDNx6sHvBAJa681KqU3AV4H3AiilXMBDwF1a69NKqY8CvwToYgy42EiM\ntHLkEm9PJz2LZiZQS3UFwszEqQW7EfgJgNb6ELAhbdtKoBf4tFLqWaBNa12Vxh1EVraS2Hm4Zvzu\nnWvYtX3ljLnxVltdgTD7cPpLaQYG0v6OK6WMp4F5wA3A/wS2A+9WSm1zPsTSIbKylcXwcHPluaPm\nXaOqmXu2LWf7hiW0Nwdwu6C9OcD2DUtmzFOIMLNxGqIZBJrS/nZrrWMT/+8FTmutXwNQSv2ElIe/\n1+6Ara0NeL3l9Wgu9IzQN2QdI/X46gjOm1OUcwWDTdl3qjDjkRihwTCtzX4Cvvy/Gk7muGXdYp7Y\n93pO+77y8z6a5tY7GlsxcHoNP/WBawv+bMvFTPieFkKtzy8Tp9+0A8AO4PsTMfjjadteBxqVUssn\nFl5vAh7OdsBQaNThUJwTj8Zpa7KOkcYjUbq7hwo+TzDYVJTjlIpirEM4neOOzZdP0ZFvnuOjf9h8\nobWnf4wzb/RWZGGyGNfQCwwNjFGt34Rq/54WSq3Oz+6m5dTA/wi4VSl1kFSmzIeVUruARq31N5VS\nHwF2Tyy4HtRa/4fD85QUu8KW2RQjrWSudmZaYr3fy58/+qIsTApCEXBk4LXWCeCTGS+fTNu+F9hY\nwLjKRjVor1SSasnVTk9LlJuuIBSH6g0Glolq0F6pBLlUjvYNjfP6uQGuXDy3rJ9JPjfdcDROd2gU\nXC6CLfWz4toJQq64kknrisFy0t09VB0DKQHVFPszqxwdDccZj0zPGMpHxbEUc7QrPosnEnzv6VMc\nPH6B8UgCgIDPw5Y1C3j/u1cUPZWymq5hqaj1Odbq/ILBJpfVtlnvwc828qkcLZeKoxV21aSP7T3N\n3sPnprw2Honz9OFzuFwu0XkRBKThR02T2Vc0W+Wov86Ny5Xy3M3o6OyuaG1AegOQI7rLcr9Kj1MQ\nqgXx4GsQq7THW9Yvtq0cDUcTXLNiHkdO9Zhu7x0M850nNR++Y1VZq0kz5zO30TqVEqBvKCw6L4KA\nGPiaxCrtMRpLWGqjGLxxcYh2m30OnrhIQ8Bb1hBI5nzsjDtAW5O/JOmUIkgnzDTEwNcYdmGYfUfP\ns3DeHFICoOb0D4fZfNUCDpy4aLlPOdMn8xUkg1SaZTHHFk8keOjx4xw4eq6kgnRyAxGKjRj4GYid\nIbAT8Eok4Vz3CIvmNXCxdxQzyfXWpgAfuDXlnVsZ+b7BcbpDoyyZX/qy73wEyYwsGiOdslCDabz/\nyRfe5JmO85OvF3vRWRRNhVIhBn4GkYshsJOoNbjYO8qC9gbO90yXh1i/ch4Nfi/33qZ47Rd9plk2\nSeAvvnuEdcva+eiOXy6pEcplPgB/cNca1C+14a/zEE8k2L2n0/Jzymb4Mz9nl+Wic3GeZKTrk1Aq\nxMDPIHIxBHbyCwaJJJzvGWVJcA5j4bhpMZG/zsM1ar7lccYjcZ5/rYvnX+vib39/C0FK48376zys\nWzFvWkpkOu3NgUnjDtafUyKZxO1yZfWUM99vVSpSjKYd1VJJLNQmYuBnCPkYgnu2LSeeSPJsxznT\nMIzB+Z4Rbly3kNuuu5y25sA0Q2IY+yO621J1E+DTf3+Ax7+yI88Z5Y5lFccE6RIGdp/TweMXpxR0\nmd0g84n5F0MbR7o+CaVEAnwzBDtD0Ds4Tt/gpY6IHreb+96j2Hr1IttjJpLw3MsXeKbjnKmXaMg4\n/MHd67KO7wN/9h9EYrGs++VLOBrnZYu0TbcLblm/aIqEgd3nZFatC1O1//OJ+RdDG8dOE1/E1YRC\nEQM/Q8jWHGPP4emhlF23ruSW9YssC5cMsjU3CbbUE/DZG7KxcII//IcDxBMJ+5PliZ3BTQK3bbx8\nSngl3yYicMlTzvZ+tyv1NFHMph3S9UkoJWLgZwj+Og9rl7Vbbj92uneakfa43dx32yq2rl9se+x0\nA5dJPJHgB8+eIZGD4R4Jx3ngkRcYDcemVNAWgp3BbTPxcO0MptVNKt1Ttnu/r87NDasX8OBHNha1\ndaB0fRJKhcTgZxDbNyydkq6Xjl28dtf2FQCWMXm7UEDmgmM2zveM8pl/2EcklqSl0cf6FfPYdatz\nY+hEs/+ebcuJxxN0nOphYDhCW3NqATmZTPK0yWJt5nEMw7r/2IUpYZ3xSIIDJy5SX+RCr9mqaCqU\nHvHgy0imNky+tDUHaHcQr80Wk7cylE6KjAAisdRdpH84wjMd5/nzR18qKHQz3cP1s2X1AnbedOW0\nfY0Ux2NnehkYjtDS6Gft8nbuujm1b7oXH/B52Hbt4mmessft5s6ty2jwmxtZI6RV6PU0MI4DML+1\nQYy7UDTEgy8D8bh9Xnau5OrNWuV577p1JR6PO+fmJgPD4az557nwVtcwu/ec4r73KEfvNzzcnTe9\ng91PneLkL/o4eOIiJ98MTfscM584QsNhnjlyjtNnB3ira3jKcccjcdwul+k1GBgOE7JQ2gwNjfOd\nJzX6zVBB11MKnIRSIwa+DDzy768UrZDFrhlGNoNh1h5vLBwjFk/iMbEncxv9tGQR9sqVlzt7uPuW\n5QV5p4/v+zkH06prMz9HuyeOc93Dpq9b5ZrbFVj56jy248gVKXASSo0Y+ALJVhUZjsY5dOKC6Xud\nFLIY4YN3rVsEySTBtEf63Xs6czIYXo+LPYfP2nqOxrzWLm/nuZfNx58P/SP5Kzymf7ZA1jqAbDIN\nZmSuXaSf07pgzPxg+VxPKXASyoEjA6+UcgNfB9aRUq76qNb6tMl+3wT6tNZ/UtAoq5BcH6+7+8fo\nDo2ZHiPfQha7c8biyZwNhp3neM+25dM6PjXWexkeKyzHPTPjJVu3psx5qstbsxYE5SprkI6xdmF2\nznUr5vHuaxfz8qneyaelVZe3WGr05HM9pcBJKAdOPfidQEBrvVkptQn4KvDe9B2UUp8A1gDPFjbE\n6sTOSN65dRl9g+Pseektjp7usfD3oLXJT2RisS4Xb83qnGPjMW67/vKcDEY2zzESjfHc0UsGzNCi\nmRPwMjLu3MgbawS53BjN5nnwxEUCPo9psZJhpHORabAal9nTz97D59i+YQlf/Nj1eHx1RMbD/ODZ\n1ydbGVqNIxfsbkZS4CQUC6cG/kbgJwBa60NKqQ3pG5VSNwDXA98AVhU0wirEzkjuP3aBI7rLthWe\nwch4lAceeTGnxTW7cx44cZHnX7locyO5ZDCyVcSmG/d0xsK5Gfe2Jj8NAS8jYzH6R8K0ZSzkZos7\nO8ncWbsspUMTjsa5Zf1i4okkx0732Hry6X1m7c55+GQ3O264gisXtfC1753kmSPWmjj5FCY5Sf8U\nhHxxauCbgYG0v+NKKa/WOqaUWgg8APw6cHeuB2xtbcDrnRlf6gs9I5baLOMR8wbW6dT7PYyF45PN\nog0j11Dv42M71+R9ToCYjebMlnWLWLKoBYCmufUEW+vpsggbWWGnaWPQ0ujjul++jN+6cx3DY1He\nuDDIFQubJ28u45EYx870mr732JlePnFnPbHBsOU8w5E42zYs5fjpbrr7x3G7IZGAE2+E+OK3X2Jo\nNELPwDjBlnrWLJvHTzvMjbEL+MLHb+CKhc2A/WcbGg7z4KMvsmn1Qo6etpBMcMOvbLqCj+9cg8ds\ntdqC3717PQ31Pg6duEBP/xjzWurZtHoh9++4Kq/jFJNgsPQS0JWk1ueXiVMDPwhT5APdWmvDxXsf\nMA/4T2AB0KCUOqm1ftTugKHQdOnaaiUejdPWlF+sNx2f181YePpN4MDR89y+cam5hK3Dc/rr3PSE\nRvnF2RANfi/xRKJk3mH/cIQnn3+TA8fO46/zTAvB9A6MW65H9PSPceaN3lTowmKebc0B3rf1SpKJ\nBM8cOYeRWt8dmrrO0RUaoyt0zjKk09YcwJtM0N09BGT/bPsGw/znwTcs551MwrvWLKCvb8RyHyt2\nbrmC2zcunbIe4eQ4xSAYbJr8TGqRWp2f3U3LqZtwALgDYCIGf9zYoLX+e631tVrrm4EvA7uzGfeZ\nhl05ezZaG/0MjERNt1lJBkxmtNhIFVgRjiY4eOIif/S/9rN7Tyffe/rUtHzwYjM8FqN3MEySS08n\nj+09nZOwVjZtFoBjFp50rmSGQHK9nlaaPmaSCfngr/NIgZNQEpx68D8CblVKHST1xPthpdQuoFFr\n/c2ija6KmZ6P7mdkPDoZdrHi6pXzLOPDmYtrZguSS+c3crF3hGg8h5hJGuORBHteOkvAV5lH/47O\nHnbccAWrLm81zUJJN7p2uf69A+M5qz2GI3G2rF7AyTf7sxZ2Ga8dPtlNyEKXxypMZdx4ukKjIjMg\nVBWupFU3gzLT3T1UHQPJk/R0vx88e8Yyg6O9+ZJxsdJ32b5hyZR89czMDgN/nZtwtLiqjeXAKJpK\n3WRcRKLxKUY3c4HZLJUyHI3zuYcO5RSqam8O8MWPXQ+k0lUz6wbMzuVxu/jSdw6bFne1N/tZu6yd\nY2f6Jm8YV69oJwkcPdUz46tRazWEYVCr8wsGmyz1Ymd9oVOhfTuNx2sw9+pXLGnh/b+yCr+LnDxU\nY0zdoVHLzI6ZaNyBSaNpPOXcsHoB992mLD/39M82/bVcUyHXr5yH1+OyTcs0e0pqajCv3l2/MjiZ\n6ZN+U39aqlGFKmXWevCl1AEZDUcnNVNCQxGCrfWsXdY+7diZN5f0MTldwL2stZ6388yQScfvdROO\n2d9AFgfncK678IVAw8PO98Z66XO6dCNtCNQxMhalfzg85YaZ7WnJ6ilp6fxGRsdjkzfgLesWsWPz\n5dOun9XThNO5VZJa9XANanV+4sGbkEs+tlPPPlMzpSs0ZurVZXqouUrzBnxu01j/u9Yt5JZrFvPl\n7x5x5OXPnePD44awRQ5/W5OfdcvbuXHtIr6y+zDhqPU92e1KZZe0NPotY9p9Q+O8fm6AKxfPzVuu\nwUxeN/OaZSvq2nHDFZbbR8djfP5DGxgLx5jb6GfJopZpxkGqUYVqZ1YaeLsf/hHdPVko48Szd6ox\nkk+Bz7yWes52Tfegn3/1bZ476lw35qp3tPEzizJ8F7Dy8haOnenlpx3nLYuqDLauX8xt1y2l3u/l\nwX9+wbTwywX81b+8PKXoKF91zXQDmvl3NgN8tmvYdvtYOGZroKUaVah2ZtYqUJGw++H3DaXkZc3S\n/CC7pnsuXl2+7wNwTXT62Xr1IoYt0iydxuZdwMZ3zufm9YtoaTI3Sn6fh0OvvD35uVjhdsEt1yxm\n1/YVtM8N8MSBn1umhRpZKZmfcbHIlpa5ZH5jQf1Qpd2eUO3MSg/ezvOy0hnp6OwmHk9w7EyvrWfv\n1Kuze19bk5/fu2stz718jo5TPfSPFC7fm04SeOG1Ll54rSvLXtm5ce2CSd333Xs6TTsoWZH5hJOp\nJplvyCybHEBTg69guYBsC+aCUElmpYG3++Fb5Tr3DoantMuzypZwojGSXshk1pLvGhXkwPELlu36\nSo3fax7zN+P46yF27+lk503vyFtTpndwnL7Bcea31k9ZbDbSKsOReN4hs2wG2ImBzoz1S7s9oVqR\nLJq0H/baZW0cO9Obl2dvli2Reex5LVOzaAwD0djg4/F9r0/J5Kn3e+nuH5sMtwR8HjZddVlqTSAH\nAbNq4YbVC/jZCWsBNCtuuWYxHrcr62Lz9g1L8jKquej2220PBpu4+PZATXdgqtUsE4NanZ9dFs2s\nNfAGxg/b6G705Itv2SoGZuJ2wV98fJPpYpxx7GVXtDM0MDYtNdNvkQ1TC7Q1+UkCIRuBNDPam/0k\nk8msN7OAz0OD30NoKFIWQxsMNvG17x3OqUBtplKrBtCgVucnaZI2ZHY3am3yTeRARwkNhfHVmQtW\nGbQ0+i3j6kZWR8DnZYjpaZC1atwhtVh9w+oFU9JFc31fLj5Humqn0+KiXFJhjX28Pi/7jxWvM5cg\nlINZb+D/5elTUxYC+4Yi9A1FuGndAq5dOZ9v/fg1WwM/p75uyg/bLBf7Qs8IY6ORvGPSM506r4sl\n8+eYpnRa0daUmwdvRq6G1niSMnT725p8XKPmT3kCmP60ZX2jt8t5L7RSWhAKYVYb+HA0zoHj5h7m\nvqMX2X80ewx5dDxKOBqfVhLf2uRjTr2P0fEofUNhWuZYF/zUKodeeZs59XV5vcdIO8ynK5NBrsVF\n33v6FHszbup7XjpLIpnk3ltTGUDTn7asb/KtTdOf4kpZKS0IuTKrDXx3/5jtDzeXRYHQUKqZ9J7D\nZ6cYBONJYHK/WWbcIZWXH47mNm+PO1UcZWSvjI7H8g7v5JK7PhqO8qxFI5CDxy/yvpuNrJrcn7bq\nPG68nqlh0GyV0oJQDma3K1GEBebWplTmS7HDLy1zfEU9XrUTT6QKrjxuNx63m/tuU7RbFCH56sy/\ntkbrPju+82QncYulj/FISuQtW9FZJhdDY/z5oy8Rn+hAkq2a2apIThCKzawz8EYl6tBoyrsuVB+9\nIVDHWDiWl0HIRntzgAc/spEtqxcU7Zgzgf3HLnC2e3iyCblVlWgkmiDg8+CfMPRGI45jZ3rZvadz\n0tBmEo7GOfmLPvtBuFy2FbBWvNU1zO49pwDn1cyCUGxmTYgmc2HNyGv311lmGOXEyFiUer/XsgrV\nCUaV5YfuWIXP5+HZjnM59USd6YSjCR54+IXJePVdN18JpLze3sHxKfumh9YyJQ9gahjEWOgcC8cs\nZRMgpbMfbKnPS5I4nZc7e7j7luWiUSNUDbPGwGfGRA2jYCgi+uvcRKIJfDnI5abTP2E4nBgEA7/X\nTSSWoK15ahWlx+1Olf0nkxWrYi036fo/ADtvegf9wxH6BsdzLpo6ort517pFtDX7eXzfz6fUHdix\nefWCKZr98XiCZ18+n/PNNTQcnlzkzVbNLNk1QjmYFQY+F6XGBr+XP/2Nq4knkjz4zy/mfGzDI7tn\n23KSySQHjl+c9C49bqjzpm4cYC2DEI4l2LJ6AXdvW85YOEYsnsQzYYviiQQut8tSIriW2X/sPPuO\nns9bRK1vKMwDD7+AL6Pzld3ntyjYwAdvveT1p9YBVoHLlXPhW8DnmfTOrSQQ7rr5Snbv6ZTsGqEs\nzAoDn8uiWWg4AskkHleqmjLXcEu6vozL5ZoSOognIB5J8O4NS0nE47Ze+OHOLl6baBDSNtEabvuG\npex56a1Z471nUsgNLUl+6pq/dFmTqYHdtX0FHreLY2d66ekfY+6cVLenbE69lWZ9ZoMRya4RSokj\nA6+UcgNfB9YBYeCjWuvTads/APwBEAOOA7+tta6Y+2kXE03n7/71KKGhiOWjfIPfS8DnJjQcoWWO\nn6sz2uxZPSUcP9PD5z90HeFowjL1bzySYDySWvg1hM2e6Tg/uYAolBb9i/7JxV0zMbFP3FnPmTd6\nicRS6wRmRCbeZ6VRPzQa4aWT5oqdxaiGlbCPkIlTD34nENBab1ZKbQK+CrwXQClVD3wRWKO1HlVK\nfQ/4VeCJYgzYKery1qx51UbeuuE5BnypH/slY76Mx54+TcepHkLDYY6d7iESifOBW1cyPBqxvIH0\n9I8xPBrhnm3LOfTKxbwWTGfD4mo10D8cpm9wnGc6zk0Ln+y86R3EBt2T4Zd8F1CNBf7DJ7tNe71C\nYR2gpKhKsMKpgb8R+AmA1vqQUmpD2rYwcIPWejTtHONUgMwvvs/rIhLL3WLW+zz8t/uuncys2L2n\nc5pk8IETF3lJv0373HpcmBdHtc9N/fAHhsNisKsUX52H//vimzz78iW9GSN8sv/YBcLROG1NKcN5\n9Yp5pjr3VnLQubRiLCS7RoqqBCucGvhmYCDt77hSyqu1jk2EYt4GUEr9HtAIPJXtgK2tDXi9xX2s\nfOjx41O++PkYd0jF5RfMb2bhvDkMDIfp6Owx3S8cTXK+Z9R0G8DwWIwfv/AWd96yHJerKPVVgkM8\nLoibfP7jkbhlw5NMUbNfvfEd/NpNV3LoxAV6+seY11LPptULuX/HVXg87oz3xjh2pjfruLasW8SS\nRS15z8fu+MfO9PKJO+sJ+HL/mQeDTXmPYSZR6/PLxKmBHwTSPym31jpm/DERo/8KsBK4U2ud1aSF\nQtYG0gnhaJwDR3OX/bVieGiUrz11khdevcjgaCz7G0wYC8d4Yt/r9IZGxbhXGDPjbjAWzq3CdM8L\nb/LXv3MDt29cOiXm3dc3XVStKzRKd2jM8lgtjT42rJrPjs2XO5KytTt+T/8YZ97ozTnsU6tyuga1\nOj+7m5bTAN0B4A6AiRj88Yzt3wACwM60UE1ZGRgOF6XwyHj8dWrc0zn5Zoi2ptklQVCLjEfi7H7q\n1OQCqt2Cpm1f2EY/D96/kV3bV+YVK0/vC5yt76wUVc1unHrwPwJuVUodJCUh8mGl1C5S4ZiXgI8A\n+4C9SimAr2mtf1SE8ebM3EZ/UXLHn3/Vrk9pfoSGwmy6ylwjfUlwDme7c5fVFSrLyV+EJrNu7LCr\nir12VZCmhtxv+FaLqfmuCQizB0cGfiLO/smMl0+m/b/iS/fxRIJonjH3UtPa5GfXrSsI+D0cPH5h\nys2nq2+UxoCX0XBMFmIrTEujj8GRCF5PqsLYjP6JqlVj8dzoCGaWolisxtxWi6nbrl3MLesX0XGq\nh4HhyLSKaGH2UrOFTrufOkW8yizlyHiUx/f9HBfTi3gi8SSReOFhIKEw2psDfP5DGxgLx/DVefhv\n3/yZ6VPg3Dk+nnzxLY6e6p6ibdRukqJoVfSUD3Z1FgePX2ROwMvAcISWRj9rl7dLiqQA1KiBz0k1\nsAxkNuoejyTY89LZSRVEofowhN6M0MmNaxeZhldCw5EpEgZmgmeZBj296Clf7Kqx09sXhobDPHPk\nHB63S1Ikhdo08APDYUIOWr4VG0vtmTy1VYTycMs1i6eFNe7Zthz9Zj9vdQ3ndax9R89PKpe2NPpY\nv2Ieu27NbzE1nVyrsQ2kT6wAVRArLwbpWQVgn7kgCGZsXb+Q+96jphngWDzJ6Li1xLAV4WhisjK6\nfzjCMx3n+cI/v2ipVZ8NO318M0R3XoAZ7sHblWgXIt8rzB5cwOLgHD7w7hWm2/Pt7mTHue4RHvzn\nF3ngw9dl9eTNdGUyF2tbGv2MhmOmbSclRVKAGW7g7Uq0jR/D/mMXbPuuCrObJHC2e4QvffsIn//Q\nhmmGN9/QSDbOdo+we8+plM6/Cdl0ZTIXa3/w7Blb3XlhdjNjQzTZ+l7G4knu2PRLJKosk0aoTt7q\nGmb3U53TXs83NJILL9v0ZTWclt7B8JTmJ4/tnRRrnVJgdc+25WzfsIT25gBuVyoLaPuGJZIiKQAz\n2IPP1vfhDXemAAAgAElEQVTyO09qXjrZZZnHLAiZHNY97LwpMq34aOdNV3Lg+IWcpQyy0T8SNlWO\nzOa0mC2aFiMFU6hdZqwHb7eQ6qvzcPDERTHuQl4Mjkb4/MPP840nXuEXbw9OetnDo5GihvnaLOLj\nhTTrzkU2QZh9zFgP3r4xsoRlBGcMjER5/tW3ef7Vt/HXublx7UJ+/V3LCLbU02UjGgaphjCj4ezF\namuXt5t629KsWyg2M9aDB0zjj1tWL5h1vUuF0hCOJnj68Dl++NwZNrzzMsv93C64Zf0i/scnN+Ov\ns27B1d7sZ+n8Ro6e6uaz3zjE5x46xO49nZOpk3bxflk0FZwwYz14MI8/Qkq1sVhZD4Jw4PgF/uD9\n6/nPg2+Ybk8Ct228nKb6Om5at9j0qfKG1Qvw17mnNYzJbMxRLN0aQYAZbuANMkvAJQdeKCbhSIK/\n/PZhy+3pMXUrA73zpndY9nJNX0At9qKp9Gmd3dSEgc8k/UfWO1iRboHCLCI9fGJloLtCo1kXUK2a\ndTtB+rQKUKMGPv1H9uobffzDDzL7kQhCcVg6v9E0fJJpoMu9gCp9WgWY4YusufCiRZ9NQSgGo+Mx\nYnZ9ACco5wJqtnx6qyIrofaoSQ/eeDw11PwEoVSYhVesKNcCai759IWEf4SZQ00a+MzHU0EoFfmE\nV8pVdSr59IJBzYVo7B5PBaHYrLq8Je/3lLrqVPLpBQNHHrxSyg18HVgHhIGPaq1Pp23fAXweiAGP\naK0fKsJYc6KY8q6CkI0DJy5y8s1QUTNUipHaKPn0AjgP0ewEAlrrzUqpTcBXgfcCKKXqgL8FrgNG\ngANKqSe01m8XY8DZKLa8qyBkwy5DJR9jXczURhEhE8C5gb8R+AmA1vqQUmpD2rZ3Aqe11iEApdR+\n4F3AvxYy0Fyx16iZjtsFySTMbfTRPywLsoJzOjp72HHDFYyFYzQ2+Hh83+t5GetSpDYWmk8vzGyc\nGvhmYCDt77hSyqu1jplsGwLmZjtga2sDXm9xPIzfvXs9DfU+nnrhFzlJvP7ZRzcxd46PL3/rBbr7\npTBKcEbv4DgPPvoioaEwAZ9nynfPMNYN9T4+tnPNtPeOR2IcO9NretxjZ3r5xJ31BHylz4kIBptK\nfo5KUuvzy8TpN2YQSP+k3BPG3WxbE9Cf7YCh0KjDoZhz+8alHDh6LquBr6tz8z8fO0JoKILfJ4+w\nQmEY6z9W37sDR89z+8al08IlXaFRui3UKnv6xzjzRm/JPfFgsInu7qGSnqOS1Or87G5aTleEDgB3\nAEzE4NNLRV8DViil2pRSPlLhmZ85PI9jcl1sDUdSzZGTIK39hJJjpetu199AUhsFpzg18D8CxpVS\nB0ktqH5aKbVLKfVxrXUU+AzwJCnD/ojW+lxxhps7dj8YQagUrU0B6v1eukKjUypKJbVRKAWuZLI6\nmmN0dw8VfSC793RKwZNQVSwJzmEsHDNdeL2URTM9tbEcAmG1GsIwqNX5BYNNlk0IatrAZ/5gmht8\n9I9IpoxQPgI+N+ORBG4XWPV/375hyZQsmUpJ/NaqATSo1fnNWgNvYPxgRsai/HcbXW9BKBatjT6u\nXTWfWDzOTzsu2O7b3hzgix+7vuJhmFo1gAa1Oj87A19zUgVmGLnAi4KN+L2zYspChQn4vdy5dRnH\nz/Rl3TdbQ21BcErNW7twND65oOWv87B5zQLLfX1i/IUicaF3lHPdQzllckmWjFAqalJNEszLvtcu\nn8e2a5Zw+uwAZ7tHpr0nEpNm3ULxePy5N2ht8mWVrJYsGaFU1GwM/n8/pXn6sHl2ZluTj/pAHSNj\nUZEnEErKnICXkfGY6bb2KmujV6sxaoNand+si8GHo3EOHL9oub1vKMK57hHWLmujpdFXxpEJs42R\n8Rged8qpcAEBnwd/XepnVy3OlVC71KSB7+4fy6kq9ejpPgbEgxdKTDwBY5E4m1cvYDwSJxxNhQL7\nhiLseeksu5/qrPAIhVqlNmPwOXpGA5ITL5SJsXCcQ6+aP1U++/J5cLnYtX1FVYRqhNqhJr9NwdYG\nAr6anJpQRNLDJeUgYbGGn0jCM0fO8dje0+Y7CIJDatIK+us83LBmYaWHIVQ54WicP7n3WrasXkB7\nsx+3K1V0tDg4J+djeIr4C+ro7JmiTyMIhVKbIRrgA+9ewam3Bnira7jSQxGqlGQSftrxFh+6YxWx\neHJSHsDrcfGtn5xk/zHrhXqAOq+by1rrTVNunWAUPEmDDqFY1KQHDxCLJxkdj5puc1smFQmzjWdf\nvshje0/jr/Mwt9HPwHCYWDzJB29VWcN80ViCs90jLJ3fSHuzH5cL2pr9OK2Xy1bwlF60Vw1U23iE\n6dSsB2+nB28l+iTMTl462cXwaIRTZwfoGwxPNH5JMh7JrfDtfM8wX/7kDcTjickngAceeYHzPfk1\nsbEqeCpmr9ZiUG3jEayp2athpwff3uznlvWLaG8O4HKBOPSzm/7hCIde7aJ3MDzZ+CVX4w6pNMi/\n+ZeXmd/agL/Og8ft5sH7N3LLNYtt6yzcLnBNxP23b1jCPduWm+5n9Go1xme0/6vUomy1jUewpmYN\nvH0DhSD33baKL37sev7onqsRh14olLdDowyNXkq79bjd3PcexWfuXmf5nmQS/uieq/nix65n1/aV\npt5vOBqno7Pb9P2VWJSttvEI9tSsgQe4Z9tytm9YQntzYDJDIt1T8td5WDK/sWLVrC6XrAfUCokk\nnDVZ0A+2NtBu8STZ1hzgysVzbXVo7EKNlVChrLbxCPbUbAweUl7Uru0ruXPrsmkNFNLjiJXSo0km\nkaeHGsHtgiXzG4HpDTvWrwyadhbLRWTMCDX2mhjVSqhQVtt4BHscGXilVD3wXWA+MAT8pta6O2Of\nTwPvn/jzP7XWDxYy0EIw9ODTMeKIglAMGgJeGgJedu/pnLb4eNfNVwKYtuLLRqE3iGJTbeMR7HHq\nwf8WcFxr/QWl1PuBzwGfMjYqpa4EPghcDySA/UqpH2mtjxU64GJgF0cUBCf4vG52P9XJMx3nJ18z\nFh8ByyfJXDBuBE5uEKWg2sYjWOPUwN8IfGXi/z8G/ixj+1vAr2it4wBKqTpg3OG58iZbT0u7OKIg\nOCE0HKHjVI/pto7OHu7cusz0STIX7EKNlaDaxiNYk9XAK6U+Anw64+W3gYGJ/w8Bc9M3aq2jQI9S\nygX8FdChtS65ZF6u+bl2ccRstDX5aQh4i1a9KFSeLasX8OobIfpHwvi87km1x3xomeMnZLHAmFmh\n6rSpttMbRKmotvEI08lq4LXWDwMPp7+mlPoh0DTxZxPQn/k+pVQAeITUDeC3s52ntbUBr7cwL+Ch\nx49PiQ0aj8gN9T4+tnPNlH23rFvME/ten3aMKxY188b5QctzbFqzkJdee7ugcQrVRXtrA9/84LWE\nBsPMnVPHZ79+gNdtvgNmbF6b+l50hcambZvXUs+yK9qp87h55N9f4dCJC3T3jxFsqWfT6oXcv+Mq\nPMUUtSmAYLAp+04zmFqfXyZOQzQHgDuAF4DbgX3pGyc89/8D7NVa/2UuBwyF8qv6yyQcjXPgqHkH\npwNHz3P7xqVTvKUdmy9ndCwyLY54181X8m8/fZ2Ozm56B8O4XakUuLYmP9eoIFuuuowfH3yjoLEK\n1YXx/QD4ed8wn7lnHT949nUOn+xmcDR7htWW1Qv49RuvIBKJmS4+rl3WztDAGLv3dE7Z3hUa44l9\nrzM6FmHX9pXFm5BDarXjkUGtzs/upuXUwP8j8C2l1H4gAuwCUEp9BjgNeICtgF8pdfvEez6rtf6Z\nw/NlJZf83PTHSbs4Yvrr9X4vY+HY5PZwNO44vCOUB7cLFs2bw8DwOENj2QtvegfH+e6TmpNvhqaE\n9r5w/3X890dfsgy9APjr3Nx7m8LjdtsuPmYrEDJi9IJQTBwZeK31KPA+k9f/Ju3PgNNBOcFpfq5V\nHDH99aYG35TX1y5rn5ItIVQHbU0+fuM2xTsWzaWpwcc3n3iFQ69mD6d53HDgxCXlyPTsl2tXmacE\nGrhclyrVMp0GwzkwlCrzcUAycRq3F2Y3NVPoVM783O0bloqBr0L6hiIEWxsmb8j33qZ48eTbxLOs\nmVpt7+js4cGPbGRsPDblBpBOZMLwphtnr8fFnsNnpyz2r10+j9YmH31D00M+dg6ICHsJhVBT35Bs\n0gTFoq05YFl+LlSWPYcv3eAb/F62rl/s+FihoXGGRyPce5si2GL+QGpmnM3EuJ45co459eaSGHYO\niAh7CYVQMx48lC8/11/n4aor23ju5QtFP7ZQGMdO9xK+JRV3HxgO81/fdSVul4vDJ7sIWUhSGAvp\nmRjG21/nYfOaRaZZV5nG2S7WPjoe5Zb1izh2pi+nAiGJ2wuFUlMG3qCU+bnGI/Ox070lOb5QGFYL\npn/2oev47pOaIybFSIuDjaadv9KN9/07rjLNuso0zvax9jC3bbycu7etyMkBKTRuLwg1aeBLSS4a\nNm4XXNZWz4Xe6TnRQmnxeVymC6b7j50nHEkQ8KUMajgSp605MzXW2nh7PLk9Heay2J+rAyLCXkKh\niIHPg1w1bDZdNZ/Xz9v3gvV5XURi5lqSLhcwS5QmPW4X8SK22IrEzY9lNPAYj6TCN1tWL+De25Rp\naqydZ53NOBdzsV+EvYRCEQOfB7lq2Bw80ZV1n2gsid/rJhybnsLR1hRg7bK2WZGp43G7qPd7GB6L\nlfW8J9+cVnw9abyNXqNO13CKKcYlwl5CIYiBz4NCNGwy8fs8JJPm3uaqy1u48+bleDxuOjp76B0s\nm05b2YnEEkRMbnL5MHdOHUNjURJ5HMYshm2XkpgPxVzsF2EvoRBqKk2y1Ni1AcyX8Uh8mqiVx+0i\n4HNz4MRFHnj4eQAe/Mh1/MFda8wOUXVYpRKWinetW8CXP7GJ379zbV7GHabGsA2PffeeU0VNSTSe\nCIphkIt5LGH2IB58ntyzbTnxRJJnO86ZptZlw1fnwu1ymTZ1jieSxCOpgxrGJZFMkixijLpUBHwe\nHvjwRn703BkOHL84GesuBR43XP/Oy7h720oa/F7ORvPXF1m/ch5ej2uyQYehO2RGR2cP45HyhpAE\noRiIgc8Tj9vNbdct5Zkj5sJmdgRbAvz2r6/mz//5pZzfc7DExrJYbF6zkAa/F5fLVdLxzm8JEI3F\n+dkrb6Pf6mfdinkkbG6AbjfUeVyEo6l9Aj4PW9Ys4J5ty6dlRFkdJjQ0TmgwnPXHInICQrUhBt4B\ncxv9tOcZiw/43Dzw4Y3E4wnq6txEctQcnwnGPeDz8MlfX0NfaNQyy2hug5cELoZGowWdq6v/0npE\n72CYvYftb7SJBITTLPd4JE4ikeRC7yhHdPbFcEiFc1qb/QwNmKe9ipyAUK2IgXeAXfqaFfPm1vP4\nvpQMca7GfaawefUCGup9/PytkGWW0cBobiEOn9dd8KIrpGoR6ryXPPd0ftpxnp92nM85DXX9ynkE\nfF6sAkGZTwKZrfoEoVKIe+EQM92brVcvornB/J7Z3T82uYCXD/666r9Et0zovcxt9NPaZK63kgse\nt6soxh1S4RYz4w6p+gI74+52pWoRctEyyiYnEI5W/xOYULuIB+8Qs/S1geEwz71snrvupA0cTBQ9\nVTnPHDnL+l9eiL/Ow5x6c8XEXNj0y5dx8s1QxbX2t169iNs2Xp5TLF3kBIRqpvrdwyonPX3NyJMv\nJka2ja8uZemtMj3MaJ5Tx41rFhR1PGYcO9PHeCRGOBpndNxZjL2x3suH7lhVtDTUfHFxyWPfdevK\nnFMS7a65yAkIlUY8+CLiJDafK5FokpZGH+uWz2PLmgV8+btHsqZpbnznZdyzbTkBv3dKJeSaZW0M\njUY5oruLIodgZJnkWumbidvt4i8+fv2UrkhHdDd9Q5daJgZ8btPUUislyHxob/bzqbvWEnSQZy5y\nAkI1Iwa+yGSWlvvqPEXLhOkfjvDsy+eJxRJZjdqW1QsmsziMUFLf4Dh7XnqLY2d66RsM47cwmvli\nZJnEI1Fnlb7JJKPjcRrrzbsiDYxE+Lvvv8x4ZHropxif7/qVQZbMd96MWeQEhGpFDHyRSTdQ3aFR\nvvZvx4qe6njyzRAtc7z0j5hnprQ1+Sb7hBr46zw803Fuir5NMYw7XMoycfoEYxbKSBf1GhgOW8b1\nw5E4W1Yv4OSb/RPG1c/IeDSnuQV8Hm5cu7BgQyxyAkK14sjAK6Xqge8C84Eh4De11tNSCZRSbuA/\ngP+jtf6nQgY6kzAKXnC5bEMW6YbJ5cpdVTE0FGbTVQs4aNFG7ho1f5qBscv28Ne5HS0CtzT62LBq\n/hQDmenNNs/x0W/RaMOgIeDF65m+uJCeX25FW3OAe29TAJPG9QfPnrG9ybQ3+1l1eSsfuDVVCVss\nStmHQBCc4PTb/VvAca31F5RS7wc+B3zKZL8vAq1OBzfTyCx4aW3y4feZhxDaMwxTY0MdP3j2dTp0\nN/0jESYUg01pbQqw69YVBPyeKZWu6VWamdjFxyPRxMTNJvcMltZGP1+4/7opDcnBPMTy54++aHvc\nt7qGeWzv6Wk547lo76fHuQ3jasx//7ELpp/92mXt3HfbquyTFIQZjlMDfyPwlYn//xj4s8wdlFJ3\nAQngJw7PMePINEh26YJmhum+9yjuvmX5pGH8/t7Tps2e16+cR4O/jntvVbzv5uV0h0bB5SLYUo+/\nzkM4Gqd3YKrcrZ0SZroX/J0nteWTQTrXrgpOGvdwNM6FnhHi0fjk+dK92VzCNvuPnWfnTVficbsm\n52/nuTc3eLlWzTe9mXncbu7cuowjusvUwB8700c4bayCUKtkNfBKqY8An854+W1gYOL/Q8DcjPes\nBnYBdwGfL3yY1Y9dCKTe76HB7yU0FM66AJduGD90xyrqA17bxTt/nWdygTCeSEyKZ2WWzOea7fHh\nO1bRkHbOlkY/c+rrGB2PThv/lCeWoTBtTeYl+sZ4D5/sJjRs7smPRxI8+MgLxBMJQkMR5jbah3YG\nR2P87JWLuNwuPvDuFdMkAQaGw4QsbrCVyk8XrRqh3LisNMntUEr9EPiy1voFpdRc4IDWenXa9q8A\nW4Ex4AogAvy+1trSm4/F4kmvd+Z+6S/0jPCJL+/B7ON0u+Brf3gL/joPrc1+Ar78HpzGIzFCg2HT\n96Zv+85/vmbaGPrXbrqSj+1cQzye4JF/f4VDJy7Q0z/GvJZ6Nq1eyP07rsLjcVseN+Dzmo7hoceP\n254vk66+UT7ypafymnsumJ1vPBLjd76yl67QdP2Y+a31/K8/3pb3dXBK+ufe3T9G0OZzFwQHWFbH\nOP2GHwDuAF4Abgf2pW/UWv+x8X+l1BeAi3bGHSAUGnU4lOogHo3T1mQeApnXUo83mcCbdDE0MGap\naWKHF6a810zgasSiyOjA0fPcvnEp/joPO7dcwe0bl07xJPv6RnI6Z/rf4WicA0fNhb7Sz5dOd4mu\n8f6Xz5meb+2ydtMnlrXL2vO+DsFgE93dTq4c7N7TOWUcXaExntj3OqNjkarSqilkjjOBWp1fMGid\n4uvUffhH4Cql1H7g48CDAEqpzyilfs3hMWc0ds1ANq1eWPRHciPen96cwio10AhJpI+10OYRuZTo\nZzK30U9rY13e52qeY/+e0FDY9HxmekHZtGWKjWjVCJXEkQevtR4F3mfy+t+YvPYFJ+eYiVgVvNy/\n4ypLL9kJuTb/NnBSMp8tXmy3aGt1Pn+dh2tXXZZXnnx7c4A/+eB6vvSdw5Yx+dYmv+n5qiE/XbRq\nhEoihU5FxMqgFDvOmq8kQD4l87lqmzst0b9n23JO/iLE2e7cbnjrV86jfW49G1bNt7wxXKOCtvOr\nZH66kxuhIBQLMfAloBQGJd2jtjMaAV8qY6d/OHvGjhnZtM3Tx+GkRD8WTzIWzq4Nn1lles+25SST\nySntAAM+DzdY5P1XC6JVI1QSMfBVjpVHffWKeTxt0s3oxrULHYck7EI/R3Q38USSY6d7pnn2d25d\nhsdXRzwSLUheF1LVsVdd0TatytTjdvPBWxV33byc7v4xSCYdiYNVAtGqESqFozTJUtDdPVQdAykB\nxczAMNh27WLcLpep0XDaJq4rNMpnv3EoL4XJ7RuWsGv7ypznGI7G+dxDh0yfPloafTx4/8Zp1bHV\nQDEyMKo9D75Ws0wManV+wWBT0dMkhTJg51EfPdXDp+5ay44brmAsHHNkNIZGI5ztGmbJ/EaaGny2\noR8rWd6Ozh7u3Los53PahSw2rJpflca9WIhWjVBuxMAXQKk9MrtwRu9gmM8/8iLtaaGSXInEYnzp\n20c41z1MIpky3ouDjfzpb1xjaXytdNCMTJAlOZ9dQhaCUC7EwDsg10yTQrHzqA2cNHj+0reP8FbX\n8OTfiWRK8OtL3z7C5z+0AZhqfNcua+PYmd6iZYJUQ/piIVR7qEUQDMTAOyBbpkmxyEdf3QiVZDM4\nQ6MRznUPm2471z3M6HjM1PharQUUkgky00IW2W7sYviFakMMfJ5kq0zMxcjmQ3o4o29o3FTrBnIv\nmjnbNWwZbkkkU9vfeUXbNOMrYRXrG3symcTlcpX8iU4Q8kUMfJ6UuzJxSoeo/jH+7vsvm8oQ5xoq\nWTK/0XLB1O1Kbc82jtnopY5HYpY39vTcfCjdE51QW5TjiU8MfJ5UqjLRX+dhSbCRa5R5RWeuoZKm\nBh+Lg41TYvAGi4ONWbNYZlpYpViEBq1v7FYtGUvxRCfMfMq1hgfOxcZmLXaiYuWoTCyGgNaf/sY1\nLJ3w5CHluS+dn8qiqRThaJyu0GjVim+1Nqdu7PlgJbomzG7MhAL3vHSWx/aeLvq5xIN3QCXj0cUI\nlfi8Xh68f+O0PPhKUE5vphACPq/lgnfA5zZV8hStGSGTcq/hiYF3QDXEo4sRKmlq8PHOK9qKNCJn\nlCsjqRhY3dgTySR7TWQjRGtGyKTca3hi4Atgtsaji0UpvJlSLlxZ3djjiYSlbIQgpFPuNTwx8ELF\ncOLNWBnwcoZ6Mm/s1fBEJ8wMyq0uKgZeqBj5eDPZDHg1hHrkiU7IhXKu4YmBFypGPt6MnQG/c+uy\nsi5cOUGqXAWDcj7xiYEXKkou3ky2WP271i2q2rZ4MyVLSCg/5Xjic2TglVL1wHeB+cAQ8Jta6+6M\nfW4HHgBcwGHgd7TWNav5Xs1Us/eYizeTLVZPMlm1bfGqIXQkzF6cuhC/BRzXWt8EfBv4XPpGpVQT\n8FfAr2qtrwfeAOYVME7BAfFEgt17OvncQ4f47DcO8bmHDrF7TyfxxPSc7UpjeDN2Db7NaG0KEGxt\nqGjxmRXZnjyqtahLqB2cGvgbgZ9M/P/HwPaM7TcAx4GvKqX2AW9nevhC6SlnxVwpyaV6uBgVvsUm\nlywhQSglWUM0SqmPAJ/OePltYGDi/0PA3Izt84BbgKuBYWCfUupnWuvOwoYr5Eq5K+ZKTbZYfTWm\nKlZKt0gQDLIaeK31w8DD6a8ppX4INE382QT0Z7ytF3hRa31xYv/nSBl7SwPf2tqA1ztzDE6+BINN\n2XcqIhd6RugbsvYePb46gvPmFPWcpZ7jpz5wLeORGKHBMK3NfgI+869vPt2l8sHJ/LasW8wT+143\neX0RSxa1FGNYRaXc39NyU+vzy8RpFs0B4A7gBeB2YF/G9iPAaqXUPFLGfxPwkN0BQ6FRh0OpfirR\n7DcejdPWZO09xiPRoo6pnHP0AkMDY5TzE3U6vx2bL2d0LDLtyWPH5surrgF0rTalNqjV+dndtJwa\n+H8EvqWU2g9EgF0ASqnPAKe11k8opT4LPDmx//e11iccnktwQL4Vc9WcaWPGTBlvNYaOhNmDK2nV\nIqjMdHcPVcdASkClPIdLOdjT49ZGDnax8rTLNcdK5ZXXqveXTq3PsVbnFww2uay2SaFTDZOL9zjT\n8rRn2ngFoZJIKV0Nktk8wyrHfKblaZdjvNXeeEQQ8kE8+Boi3/BFubWpC6WU4xVJAaEWkW9uDZFP\nYVM4GicSjdtWiFZbnna2itZCxlsrRWGCkI4Y+Boh1/BFunzBA4+8yMh41PQ91diNqFT9cGdaqEoQ\nckVCNDVCruGLzEVKo5dowOchEo1XfTeiUmhp5/LZlap4ShBKiRj4GiGXsng7T7XB7+W/3XctwZb6\nqvPc0ylFXrlICgi1ioRoaoRcwhd2nmr/cBif113Vxj0dO/VJJ8fKN/Qj2TbCTEA8+BoiW/hCPFVr\ncg39SLaNMJMQA19DZAtflLvh70wi19CPFFoJMwlxOWoQu/BFNeqmVxN2n51k2wgzDfHgZxkifuWc\nmVYYJgjiwc9SirlIOVsoZaGVIJQCMfCCkCOlKrQShFIhIRpByINSFFoJQqkQAy8IeSBrGMJMQgy8\nIDjAWMMQhGpGYvCCIAg1ihh4QRCEGsVRiEYpVQ98F5gPDAG/qbXuztjnD0k1404Af6G1/lGBYxUE\nQRDywKkH/1vAca31TcC3gc+lb1RKtQCfAjYD7wH+rpBBCoIgCPnj1MDfCPxk4v8/BrZnbB8BfgHM\nmfiXcHgeQRAEwSFZQzRKqY8An854+W1gYOL/Q8Bck7e+BbwKeID/ke08ra0NeL21m24WDDZVeggl\np9bnWOvzg9qfY63PL5OsBl5r/TDwcPprSqkfAsYn1QT0Z7ztdmAh8I6Jv59USh3QWr9gORCvx5Xr\noAVBEITsOA3RHADumPj/7cC+jO0hYAwIa63HSd0AWhyeSxAEQXCA00KnfwS+pZTaD0RIZcuglPoM\ncFpr/YRSajtwSCmVAPYDTxVjwIIgCEJuuJLJZKXHIAiCIJQAKXQSBEGoUcTAC4Ig1Chi4AVBEGoU\nUZMsAkqp64G/1FrfrJRaDjwKJIETwO9orRNp+7qBrwPrgDDwUa316fKPOj/ymePE/keAwYk/f661\n/nA5x5sv6fNLe+1vAa21/qeMfWf8NUx7zXSOE9tm1DWEad/Tq4F/AOKkrtNvaK3fTtt3Rl7HfBAP\nvmwlKI0AAAIkSURBVECUUn8M/L9AYOKlvwE+NyHj4ALem/GWnUBAa70Z+BPgq+Uaq1PynaNSKgC4\ntNY3T/yrasOQOT+lVFAp9WPg1yzeMuOvYbY5zrRrCKbf068BvzdxQ/sh8P9kvGXGXcd8EQNfOGeA\n/5r297XAsxP/N5NxmJR50FofAjaUeoBFIN85rgMalFL/Vym1Vym1qQxjLITM+TUCXwC+Y7F/LVzD\nbHOcadcQps/x/Vrrlyf+7wXGM/afidcxL8TAF4jW+gdANO0ll9bayD01k3Fo5pLMA0BcKVXVoTIH\ncxwF/hq4Dfgk8L+reY6Z89Na/1xr/bzNW2b8NcxhjjPqGoLpHC8AKKVuAH4X+NuMt8y465gvNTWZ\nKiE9Fm0m4zDIJZkHALfWOlbyURWXbHPsJFXwlgQ6lVK9pKQr3irT+EpNLVzDbNTENVRK3QP8KfBf\nMiXNmQXXUTz44tOhlLp54v9mMg6TMg8Tj73Hyze0opFtjvczEc9USi0i5SldKNvoSk8tXMNszPhr\nqJS6l5TnfrPW+nWTXWr+OooHX3z+EHhIKeUDXgP+DUApZejm/wi4VSl1kNQCZdUvXpmQbY4PA49O\nSFkkgftrwTOqsWtoSq1cQ6WUB/h74E3gh0opgGe11g/MhutoIFIFgiAINYqEaARBEGoUMfCCIAg1\nihh4QRCEGkUMvCAIQo0iBl4QBKFGEQMvCIJQo4iBFwRBqFHEwAuCINQo/z94Q9bAnTZH+wAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12f62dac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(result.predict(X_train[top15]), result.resid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
